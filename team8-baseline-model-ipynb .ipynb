{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":2838990,"sourceType":"datasetVersion","datasetId":1737111},{"sourceId":4838716,"sourceType":"datasetVersion","datasetId":2804156},{"sourceId":6355064,"sourceType":"datasetVersion","datasetId":3660235}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":729.56026,"end_time":"2025-10-24T15:48:42.210230","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-24T15:36:32.649970","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"043a78a335b8415880dd0da806c09438":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"05302b7d73494a10a94a2dc0de65751c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30183693c79345318e8a3ecc88348414","IPY_MODEL_d7be2dc4d8624b5e8d1de337b338d139","IPY_MODEL_68bf8f5642e9490e94ed810f704509d8"],"layout":"IPY_MODEL_2357a40d47874ebbb699c9080d5280e2","tabbable":null,"tooltip":null}},"118953ecbdf8484298f2a987ed6efe24":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2357a40d47874ebbb699c9080d5280e2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30183693c79345318e8a3ecc88348414":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c9157cbfa1ba4594b629202dc1696be5","placeholder":"â€‹","style":"IPY_MODEL_af42f9b294fe44908834110a6ead97da","tabbable":null,"tooltip":null,"value":"Batches:â€‡100%"}},"312978b638f14ebf8710a1f531640f0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_aabf400781bd4cf58db206b42e800e83","placeholder":"â€‹","style":"IPY_MODEL_7061544087ae43a5b4c76af65cb5e22c","tabbable":null,"tooltip":null,"value":"â€‡450/450â€‡[03:23&lt;00:00,â€‡16.85it/s]"}},"4666507cf9324c2993e61b3deda2698f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cd40b42fbd2942cba8539003c50c5fc9","placeholder":"â€‹","style":"IPY_MODEL_043a78a335b8415880dd0da806c09438","tabbable":null,"tooltip":null,"value":"Batches:â€‡100%"}},"64fca46ebcdd4d2d93e578aba7052b74":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68bf8f5642e9490e94ed810f704509d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_64fca46ebcdd4d2d93e578aba7052b74","placeholder":"â€‹","style":"IPY_MODEL_e119b1124b864ed794ecf204ff4219bb","tabbable":null,"tooltip":null,"value":"â€‡1/1â€‡[00:00&lt;00:00,â€‡37.35it/s]"}},"7061544087ae43a5b4c76af65cb5e22c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"aabf400781bd4cf58db206b42e800e83":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af42f9b294fe44908834110a6ead97da":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b8026d0ba6fd452c8eeb6d3179021fe9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9157cbfa1ba4594b629202dc1696be5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd40b42fbd2942cba8539003c50c5fc9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d03451a5732c41829eabb5385f1e0000":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b8026d0ba6fd452c8eeb6d3179021fe9","max":450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d81a666ed60745e6b4853e6edf238cfb","tabbable":null,"tooltip":null,"value":450}},"d7be2dc4d8624b5e8d1de337b338d139":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e8fd271b53dc450d8d1f33b5e57fdaf6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8de2cac119044e19b5eabf47dfa1d22","tabbable":null,"tooltip":null,"value":1}},"d81a666ed60745e6b4853e6edf238cfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e119b1124b864ed794ecf204ff4219bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e8de2cac119044e19b5eabf47dfa1d22":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8fd271b53dc450d8d1f33b5e57fdaf6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec8ed3b0a5042ccb892473ce9ce06bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4666507cf9324c2993e61b3deda2698f","IPY_MODEL_d03451a5732c41829eabb5385f1e0000","IPY_MODEL_312978b638f14ebf8710a1f531640f0c"],"layout":"IPY_MODEL_118953ecbdf8484298f2a987ed6efe24","tabbable":null,"tooltip":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"de914c02-57ee-4034-9a62-a442a53618cd","cell_type":"markdown","source":"###  1: å¯¼å…¥åº“ä¸åŠ è½½æ•°æ®\n\n**ä»£ç åˆ†æ:**\n\n*   **é›†ä¸­å¯¼å…¥**: åœ¨ Notebook çš„æœ€å¼€å§‹ï¼Œæˆ‘ä»¬ä¸€æ¬¡æ€§å¯¼å…¥æ‰€æœ‰éœ€è¦ç”¨åˆ°çš„ Python åº“ï¼ŒåŒ…æ‹¬ç”¨äºæ•°æ®å¤„ç†çš„ `pandas`ã€ç§‘å­¦è®¡ç®—çš„ `numpy`ï¼Œä»¥åŠ `scikit-learn` ä¸­ç”¨äºç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„å„ä¸ªæ¨¡å—ã€‚è¿™æ˜¯ä¸€ä¸ªè‰¯å¥½çš„ç¼–ç¨‹ä¹ æƒ¯ï¼Œä½¿å¾—ä»£ç çš„ä¾èµ–å…³ç³»ä¸€ç›®äº†ç„¶ã€‚\n*   **æ•°æ®åŠ è½½**: æˆ‘ä»¬ä½¿ç”¨ `pd.read_csv()` æ¥åŠ è½½ç«èµ›æä¾›çš„ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶ï¼š`train.csv` (è®­ç»ƒæ•°æ®)ï¼Œ`test.csv` (æµ‹è¯•æ•°æ®)ï¼Œå’Œ `sample_submission.csv` (æäº¤æ ¼å¼ç¤ºä¾‹)ã€‚\n*   **å¥å£®æ€§**: æ•´ä¸ªåŠ è½½è¿‡ç¨‹è¢«åŒ…è£¹åœ¨ `try...except FileNotFoundError` å—ä¸­ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯ï¼Œå¦‚æœå› ä¸ºæŸç§åŸå› ï¼ˆä¾‹å¦‚æ•°æ®é›†æœªæ·»åŠ åˆ° Notebookï¼‰å¯¼è‡´æ–‡ä»¶è·¯å¾„æ— æ•ˆï¼Œç¨‹åºä¸ä¼šç›´æ¥å´©æºƒï¼Œè€Œæ˜¯ä¼šæ‰“å°å‡ºä¸€æ¡æ¸…æ™°çš„é”™è¯¯æç¤ºä¿¡æ¯ï¼Œä¾¿äºæˆ‘ä»¬å¿«é€Ÿå®šä½é—®é¢˜ã€‚","metadata":{}},{"id":"4657eb5c","cell_type":"code","source":"# ===  1: å¯¼å…¥æ‰€æœ‰å¿…éœ€çš„åº“ä¸åŠ è½½æ•°æ® ===\n\n# æ•°æ®å¤„ç†ä¸ç§‘å­¦è®¡ç®—\nimport pandas as pd\nimport numpy as np\n\n# ç‰¹å¾å·¥ç¨‹\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\n\n# æ¨¡å‹ä¸è¯„ä¼°\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\n# æ·±åº¦å­¦ä¹ åµŒå…¥æ¨¡å‹\nfrom sentence_transformers import SentenceTransformer\n\nprint(\"ğŸš€ Team 8 Baseline & Embedding Model Pipeline å¯åŠ¨ï¼\")\n\n# --- åŠ è½½æ•°æ®é›† ---\n# ä½¿ç”¨ try-except ç»“æ„ç¡®ä¿æ•°æ®åŠ è½½çš„å¥å£®æ€§\ntry:\n    train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n    sample = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\n    print(\"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!\")\n    print(f\"  è®­ç»ƒé›†å¤§å°: {train.shape}\")\n    print(f\"  æµ‹è¯•é›†å¤§å°: {test.shape}\")\nexcept FileNotFoundError:\n    print(\"âŒ æ•°æ®åŠ è½½å¤±è´¥! è¯·æ£€æŸ¥ç«èµ›æ•°æ®é›†æ˜¯å¦å·²æ­£ç¡®æ·»åŠ åˆ° Notebook.\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":33.715467,"end_time":"2025-10-24T15:37:09.942063","exception":false,"start_time":"2025-10-24T15:36:36.226596","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:45:52.121256Z","iopub.execute_input":"2025-10-28T02:45:52.121570Z","iopub.status.idle":"2025-10-28T02:46:24.443951Z","shell.execute_reply.started":"2025-10-28T02:45:52.121549Z","shell.execute_reply":"2025-10-28T02:46:24.443195Z"}},"outputs":[{"name":"stderr","text":"2025-10-28 02:46:07.027482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761619567.215280      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761619567.273280      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸš€ Team 8 Baseline & Embedding Model Pipeline å¯åŠ¨ï¼\nâœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!\n  è®­ç»ƒé›†å¤§å°: (57477, 9)\n  æµ‹è¯•é›†å¤§å°: (3, 4)\n","output_type":"stream"}],"execution_count":1},{"id":"b1d7c1ba","cell_type":"markdown","source":"###  2: ç‰¹å¾å·¥ç¨‹\n\n**ä»£ç åˆ†æ:**\n\n*   **æ ¸å¿ƒåŸåˆ™**: ä¸ºäº†ä¿è¯æ¨¡å‹çš„å…¬å¹³æ€§å’Œæœ‰æ•ˆæ€§ï¼Œæ‰€æœ‰å¯¹è®­ç»ƒé›† `train` è¿›è¡Œçš„ç‰¹å¾å·¥ç¨‹ï¼Œéƒ½**å¿…é¡»ä»¥å®Œå…¨ç›¸åŒçš„æ–¹å¼**åº”ç”¨åˆ°æµ‹è¯•é›† `test` ä¸Šã€‚è¿™ç¡®ä¿äº†æ¨¡å‹åœ¨è®­ç»ƒå’Œé¢„æµ‹æ—¶çœ‹åˆ°çš„æ•°æ®ç»“æ„æ˜¯å®Œå…¨ä¸€è‡´çš„ï¼Œä»è€Œé¿å…äº† `KeyError` ç­‰å¸¸è§é”™è¯¯ã€‚\n\n*   **1. æ ‡ç­¾ç”Ÿæˆ (`label` - ä»…é™è®­ç»ƒé›†)**:\n    *   **ä½œç”¨**: å°†è®­ç»ƒæ•°æ®ä¸­ `winner_model_a`, `winner_model_b`, `winner_tie` è¿™ä¸‰åˆ—ï¼ˆone-hot ç¼–ç æ ¼å¼ï¼‰è½¬æ¢ä¸ºä¸€ä¸ªå•ä¸€çš„ã€å¤šåˆ†ç±»çš„æ ‡ç­¾åˆ—ã€‚\n    *   **æ–¹æ³•**: `.argmax(axis=1)` ä¼šæ²¿ç€æ¯ä¸€è¡ŒæŸ¥æ‰¾æœ€å¤§å€¼çš„ç´¢å¼•ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ `winner_model_a` æ˜¯1ï¼Œå®ƒçš„ç´¢å¼•æ˜¯0ï¼›å¦‚æœ `winner_model_b` æ˜¯1ï¼Œç´¢å¼•æ˜¯1ï¼›å¦‚æœæ˜¯å¹³å±€ï¼Œç´¢å¼•æ˜¯2ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†ä¸€ä¸ªé€‚åˆåˆ†ç±»æ¨¡å‹è®­ç»ƒçš„ç›®æ ‡å˜é‡ `y` (å€¼ä¸º 0, 1, 2)ã€‚\n\n*   **2. æ–‡æœ¬ä¸é•¿åº¦ç‰¹å¾å·¥ç¨‹ (é’ˆå¯¹ `train` å’Œ `test` é›†)**:\n    *   **æ–‡æœ¬æ‹¼æ¥ (`text`)**: æˆ‘ä»¬å°† `prompt` ä¸ä¸¤ä¸ª `response` (`response_a`, `response_b`) åˆ†åˆ«æ‹¼æ¥ï¼Œç„¶åä½¿ç”¨ä¸€ä¸ªç‰¹æ®Šçš„åˆ†éš”ç¬¦ `[SEP]` å°†ä¸¤ä¸ªå®Œæ•´çš„å“åº”æ–‡æœ¬è¿æ¥èµ·æ¥ã€‚`[SEP]` åˆ†éš”ç¬¦ä¸ºæ¨¡å‹æä¾›äº†ä¸€ä¸ªæ˜ç¡®çš„è¾¹ç•Œï¼Œæœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°åŒºåˆ†å’Œæ¯”è¾ƒä¸¤ä¸ªä¸åŒçš„å“åº”ã€‚\n    *   **é•¿åº¦ç‰¹å¾ (`..._len`)**: æˆ‘ä»¬æå–äº† `prompt`, `response_a`, å’Œ `response_b` çš„å­—ç¬¦é•¿åº¦ä½œä¸ºé¢å¤–çš„æ•°å€¼ç‰¹å¾ã€‚æ–‡æœ¬é•¿åº¦æœ¬èº«åœ¨å¾ˆå¤šNLPä»»åŠ¡ä¸­éƒ½æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„ä¿¡å·ã€‚","metadata":{"papermill":{"duration":0.001833,"end_time":"2025-10-24T15:37:09.946018","exception":false,"start_time":"2025-10-24T15:37:09.944185","status":"completed"},"tags":[]}},{"id":"75fb844b","cell_type":"code","source":"# ===  2: ç‰¹å¾å·¥ç¨‹ (å¯¹ train å’Œ test é›†è¿›è¡Œä¸€è‡´æ€§å¤„ç†) ===\n\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ Step 1: ç‰¹å¾å·¥ç¨‹ ---\")\n\n# --- 1. å¤„ç†è®­ç»ƒé›† (train) ---\n# å°† one-hot ç¼–ç çš„æ ‡ç­¾è½¬æ¢ä¸ºå•ä¸€çš„å¤šåˆ†ç±»æ ‡ç­¾ (0, 1, 2)\ntrain['label'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values.argmax(axis=1)\n\n# åˆ›å»ºåŒ…å« prompt å’Œ response çš„å®Œæ•´æ–‡æœ¬\ntrain['text_a'] = train['prompt'] + \" \" + train['response_a']\ntrain['text_b'] = train['prompt'] + \" \" + train['response_b']\n\n# ä½¿ç”¨ [SEP] åˆ†éš”ç¬¦è¿æ¥ä¸¤ä¸ªå“åº”ï¼Œä¾¿äºæ¨¡å‹å¯¹æ¯”\ntrain['text'] = train['text_a'] + \" [SEP] \" + train['text_b']\n\n# è®¡ç®—é•¿åº¦ç‰¹å¾\ntrain['prompt_len'] = train['prompt'].str.len()\ntrain['resp_a_len'] = train['response_a'].str.len()\ntrain['resp_b_len'] = train['response_b'].str.len()\n\n\n# --- 2. ç”¨å®Œå…¨ç›¸åŒçš„æ–¹æ³•å¤„ç†æµ‹è¯•é›† (test) ---\n# æ³¨æ„ï¼šæµ‹è¯•é›†æ²¡æœ‰ 'label' åˆ—ï¼Œæ‰€ä»¥ä¸éœ€è¦å¤„ç†\ntest['text_a'] = test['prompt'] + \" \" + test['response_a']\ntest['text_b'] = test['prompt'] + \" \" + test['response_b']\ntest['text'] = test['text_a'] + \" [SEP] \" + test['text_b']\ntest['prompt_len'] = test['prompt'].str.len()\ntest['resp_a_len'] = test['response_a'].str.len()\ntest['resp_b_len'] = test['response_b'].str.len()\n\nprint(\"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆã€‚\")","metadata":{"papermill":{"duration":0.559434,"end_time":"2025-10-24T15:37:10.507378","exception":false,"start_time":"2025-10-24T15:37:09.947944","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:46:24.445313Z","iopub.execute_input":"2025-10-28T02:46:24.445554Z","iopub.status.idle":"2025-10-28T02:46:25.035564Z","shell.execute_reply.started":"2025-10-28T02:46:24.445536Z","shell.execute_reply":"2025-10-28T02:46:25.034851Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ Step 1: ç‰¹å¾å·¥ç¨‹ ---\nâœ… ç‰¹å¾å·¥ç¨‹å®Œæˆã€‚\n","output_type":"stream"}],"execution_count":2},{"id":"6d455a98","cell_type":"markdown","source":"###  3: Baseline æ¨¡å‹ (è¯è¢‹ + é€»è¾‘å›å½’)\n\n**ä»£ç åˆ†æ:**\n\n*   **1. å‘é‡åŒ–**:\n    *   **æ–‡æœ¬å‘é‡åŒ– (`CountVectorizer`)**: æˆ‘ä»¬ä½¿ç”¨â€œè¯è¢‹æ¨¡å‹â€(Bag of Words)å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºæ•°å€¼çŸ©é˜µã€‚`max_features=5000` å‚æ•°é™åˆ¶äº†åªä½¿ç”¨æœ€å¸¸è§çš„ 5000 ä¸ªè¯/è¯ç»„ä½œä¸ºç‰¹å¾ï¼Œä»¥æ§åˆ¶ç»´åº¦ã€‚`ngram_range=(1,2)` å‚æ•°è®©æ¨¡å‹åŒæ—¶è€ƒè™‘å•ä¸ªè¯ï¼ˆunigramsï¼‰å’Œç›¸é‚»çš„è¯å¯¹ï¼ˆbigramsï¼‰ï¼Œèƒ½æ•æ‰åˆ°æ›´ä¸°å¯Œçš„çŸ­è¯­ä¿¡æ¯ã€‚\n    *   **æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ– (`StandardScaler`)**: å¯¹æˆ‘ä»¬ä¹‹å‰åˆ›å»ºçš„é•¿åº¦ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä½¿å…¶å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ã€‚è¿™ä¸€æ­¥è‡³å…³é‡è¦ï¼Œå› ä¸ºé€»è¾‘å›å½’ç­‰æ¨¡å‹å¯¹ç‰¹å¾çš„å°ºåº¦å¾ˆæ•æ„Ÿï¼Œæ ‡å‡†åŒ–å¯ä»¥é˜²æ­¢æ¨¡å‹è¿‡åˆ†åé‡äºæ•°å€¼èŒƒå›´è¾ƒå¤§çš„ç‰¹å¾ã€‚\n    *   **ç‰¹å¾åˆå¹¶ (`np.hstack`)**: å°†å¤„ç†å¥½çš„æ–‡æœ¬ç‰¹å¾çŸ©é˜µå’Œæ•°å€¼ç‰¹å¾çŸ©é˜µæ°´å¹³æ‹¼æ¥ï¼Œå½¢æˆæœ€ç»ˆç”¨äºè®­ç»ƒåŸºçº¿æ¨¡å‹çš„å®Œæ•´ç‰¹å¾çŸ©é˜µ `X_baseline`ã€‚\n\n*   **2. è®­ç»ƒä¸éªŒè¯**:\n    *   **æ•°æ®åˆ’åˆ† (`train_test_split`)**: æˆ‘ä»¬å°†ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾æŒ‰ 8:2 çš„æ¯”ä¾‹åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚`random_state=42` ç¡®ä¿äº†æ¯æ¬¡åˆ’åˆ†çš„ç»“æœéƒ½ä¸€æ ·ï¼Œä¿è¯äº†å®éªŒçš„å¯å¤ç°æ€§ã€‚\n    *   **æ¨¡å‹è®­ç»ƒ (`LogisticRegression`)**: æˆ‘ä»¬é€‰ç”¨é€»è¾‘å›å½’ä½œä¸ºåŸºçº¿åˆ†ç±»å™¨ã€‚å®ƒæ˜¯ä¸€ä¸ªç®€å•ã€å¿«é€Ÿä¸”è§£é‡Šæ€§å¼ºçš„çº¿æ€§æ¨¡å‹ï¼Œéå¸¸é€‚åˆä½œä¸ºé¡¹ç›®çš„èµ·ç‚¹ã€‚æˆ‘ä»¬è®¾ç½® `max_iter=1000` æ¥å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå……åˆ†è®­ç»ƒå¹¶æ”¶æ•›ï¼Œé¿å… `ConvergenceWarning`ã€‚\n    *   **æ€§èƒ½è¯„ä¼°**: æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒåï¼Œæˆ‘ä»¬åœ¨ä»æœªè§è¿‡çš„éªŒè¯é›†ä¸Šè¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä½¿ç”¨ç«èµ›çš„å®˜æ–¹è¯„ä¼°æŒ‡æ ‡ `log_loss` æ¥è®¡ç®—éªŒè¯åˆ†æ•°ã€‚è¿™ä¸ªåˆ†æ•°å¯ä»¥å¸®åŠ©æˆ‘ä»¬åœ¨æäº¤å‰å¿«é€Ÿè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚","metadata":{"papermill":{"duration":0.002039,"end_time":"2025-10-24T15:37:10.511756","exception":false,"start_time":"2025-10-24T15:37:10.509717","status":"completed"},"tags":[]}},{"id":"609abcdf","cell_type":"code","source":"# ===  3: Baseline æ¨¡å‹ (è¯è¢‹ + é€»è¾‘å›å½’) ===\n\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ Baseline æ¨¡å‹ ---\")\n\n# --- 1. å‘é‡åŒ– ---\n# æ–‡æœ¬ç‰¹å¾ (Bag of Words)ï¼Œè€ƒè™‘ unigrams å’Œ bigrams\nvectorizer = CountVectorizer(max_features=5000, ngram_range=(1,2))\nX_text_train = vectorizer.fit_transform(train['text'])\nX_text_test = vectorizer.transform(test['text'])\n\n# æ•°å€¼ç‰¹å¾ (é•¿åº¦)ï¼Œå¹¶è¿›è¡Œæ ‡å‡†åŒ–\nscaler = StandardScaler()\nnum_features_train = train[['prompt_len','resp_a_len','resp_b_len']]\nnum_features_test = test[['prompt_len','resp_a_len','resp_b_len']]\nX_num_train = scaler.fit_transform(num_features_train)\nX_num_test = scaler.transform(num_features_test)\n\n# åˆå¹¶æ–‡æœ¬ç‰¹å¾å’Œæ•°å€¼ç‰¹å¾\nX_baseline = np.hstack([X_text_train.toarray(), X_num_train])\nX_test_baseline = np.hstack([X_text_test.toarray(), X_num_test])\ny = train['label']\n\n# --- 2. è®­ç»ƒä¸éªŒè¯ ---\n# å°†åŸºçº¿æ¨¡å‹çš„ç‰¹å¾é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\nX_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n    X_baseline, y, test_size=0.2, random_state=42\n)\n\n# è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹ï¼Œå¢åŠ  max_iter ä»¥é¿å…æ”¶æ•›è­¦å‘Š\nclf_base = LogisticRegression(max_iter=1000)\nclf_base.fit(X_train_base, y_train_base)\n\n# åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½\ny_pred_val_base = clf_base.predict_proba(X_val_base)\nvalidation_score_base = log_loss(y_val_base, y_pred_val_base)\nprint(f\"ğŸ“Š Validation LogLoss (Baseline): {validation_score_base:.5f}\")\n\n# æ³¨æ„ï¼šæˆ‘ä»¬ä¸å†ä»æ­¤æ¨¡å‹ç”Ÿæˆ submission.csvï¼Œæœ€ç»ˆæäº¤æ–‡ä»¶å°†ç”±æ›´å¼ºçš„æ¨¡å‹ç”Ÿæˆã€‚","metadata":{"papermill":{"duration":463.333965,"end_time":"2025-10-24T15:44:53.847727","exception":false,"start_time":"2025-10-24T15:37:10.513762","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:46:25.038483Z","iopub.execute_input":"2025-10-28T02:46:25.038680Z","iopub.status.idle":"2025-10-28T02:54:27.294403Z","shell.execute_reply.started":"2025-10-28T02:46:25.038664Z","shell.execute_reply":"2025-10-28T02:54:27.293862Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ Baseline æ¨¡å‹ ---\nğŸ“Š Validation LogLoss (Baseline): 1.28668\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":3},{"id":"c8646d4d","cell_type":"markdown","source":"### å•å…ƒæ ¼ 4: Embedding æ¨¡å‹ (MiniLM)\n\n**ä»£ç åˆ†æ:**\n\n*   **1. æ¨¡å‹åŠ è½½ (`SentenceTransformer`)**:\n    *   **ä½œç”¨**: æˆ‘ä»¬åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„ Transformer æ¨¡å‹ `all-MiniLM-L6-v2`ã€‚ä¸è¯è¢‹æ¨¡å‹ä¸åŒï¼Œå®ƒèƒ½å¤Ÿå°†æ•´ä¸ªå¥å­è½¬æ¢ä¸ºä¸€ä¸ªå›ºå®šé•¿åº¦çš„ã€åŒ…å«ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯çš„å‘é‡ï¼ˆå³â€œåµŒå…¥â€æˆ– Embeddingï¼‰ã€‚\n    *   **ç¦»çº¿æ¨¡å¼**: ä¸ºäº†æ»¡è¶³ç«èµ›çš„å¯å¤ç°æ€§è¦æ±‚ï¼ˆé€šå¸¸è¦æ±‚å…³é—­ç½‘ç»œï¼‰ï¼Œæˆ‘ä»¬ä»é¢„å…ˆæ·»åŠ åˆ° Notebook çš„ Kaggle æ•°æ®é›†è·¯å¾„ (`/kaggle/input/...`) åŠ è½½æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä»ç½‘ç»œä¸‹è½½ã€‚`device='cuda'` å‚æ•°æŒ‡å®šä½¿ç”¨ GPU è¿›è¡Œè®¡ç®—ï¼Œå¯ä»¥æå¤§åœ°åŠ é€Ÿåç»­çš„ç¼–ç è¿‡ç¨‹ã€‚\n\n*   **2. ç”Ÿæˆå¥å‘é‡ (`model.encode`)**:\n    *   **ä½œç”¨**: è¿™æ˜¯æ ¸å¿ƒæ­¥éª¤ã€‚æˆ‘ä»¬å°†æ¯ä¸ªæ ·æœ¬çš„æ–‡æœ¬è¾“å…¥åˆ° MiniLM æ¨¡å‹ä¸­ï¼Œè¾“å‡ºä¸€ä¸ªå›ºå®šç»´åº¦ï¼ˆå¯¹äº MiniLM æ˜¯ 384 ç»´ï¼‰çš„å‘é‡ã€‚\n    *   **å¯¹æ¯”**: è¿™é‡Œçš„ç‰¹å¾ä¸å†æ˜¯è¯è¯­çš„å‡ºç°æ¬¡æ•°ï¼Œè€Œæ˜¯æ·±å±‚è¯­ä¹‰çš„å‘é‡è¡¨ç¤ºã€‚è¿™é€šå¸¸ä¼šå¸¦æ¥æ¯”è¯è¢‹æ¨¡å‹æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚`batch_size=128` å‚æ•°å…è®¸æ¨¡å‹åœ¨ GPU ä¸Šè¿›è¡Œæ‰¹é‡å¤„ç†ï¼Œè¿›ä¸€æ­¥æå‡äº†ç¼–ç æ•ˆç‡ã€‚\n\n*   **3. è®­ç»ƒä¸éªŒè¯**:\n    *   **æ•°æ®åˆ’åˆ†**: ä¸ Baseline æ¨¡å‹ç±»ä¼¼ï¼Œæˆ‘ä»¬åŒæ ·å°†ç”Ÿæˆçš„å¥å‘é‡ `train_emb` åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œä»¥ä¾¿è¿›è¡Œå…¬å¹³çš„æ€§èƒ½æ¯”è¾ƒã€‚\n    *   **æ¨¡å‹è®­ç»ƒ**: æˆ‘ä»¬å†æ¬¡ä½¿ç”¨é€»è¾‘å›å½’åˆ†ç±»å™¨ï¼Œä½†è¿™æ¬¡çš„è¾“å…¥ç‰¹å¾æ˜¯é«˜è´¨é‡çš„å¥å‘é‡ã€‚\n    *   **æ€§èƒ½è¯„ä¼°**: æˆ‘ä»¬è®¡ç®—å¹¶æ‰“å°å‡º Embedding æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„ `log_loss` åˆ†æ•°ã€‚é€šè¿‡å¯¹æ¯”è¿™ä¸ªåˆ†æ•°å’Œ Baseline æ¨¡å‹çš„éªŒè¯åˆ†æ•°ï¼Œæˆ‘ä»¬å¯ä»¥é‡åŒ–åœ°è¯„ä¼°å‡ºä»è¯è¢‹æ¨¡å‹å‡çº§åˆ°åµŒå…¥æ¨¡å‹æ‰€å¸¦æ¥çš„æ€§èƒ½æå‡ã€‚\n\n*   **4. ç”Ÿæˆæœ€ç»ˆæäº¤æ–‡ä»¶**:\n    *   **é¢„æµ‹**: ä½¿ç”¨è®­ç»ƒå¥½çš„ Embedding æ¨¡å‹å¯¹æµ‹è¯•é›†çš„å¥å‘é‡ `test_emb` è¿›è¡Œé¢„æµ‹ã€‚\n    *   **æ–‡ä»¶ç”Ÿæˆ**: å°†é¢„æµ‹å‡ºçš„æ¦‚ç‡ä¿å­˜ä¸º `submission.csv` æ–‡ä»¶ã€‚**æ–‡ä»¶åå¿…é¡»æ˜¯ `submission.csv`**ï¼Œä»¥ç¬¦åˆ Kaggle ç«èµ›çš„æäº¤è¦æ±‚ã€‚è¿™ä¸ªæ–‡ä»¶å°†è¦†ç›–æ‰ä¹‹å‰å¯èƒ½å­˜åœ¨çš„ä»»ä½•åŒåæ–‡ä»¶ï¼Œç¡®ä¿æœ€ç»ˆæäº¤çš„æ˜¯æˆ‘ä»¬æ›´å¼ºçš„ Embedding æ¨¡å‹çš„ç»“æœã€‚","metadata":{"papermill":{"duration":0.002059,"end_time":"2025-10-24T15:44:53.852130","exception":false,"start_time":"2025-10-24T15:44:53.850071","status":"completed"},"tags":[]}},{"id":"8b1ccc5a","cell_type":"code","source":"# ===  4: Embedding æ¨¡å‹ (MiniLM + é€»è¾‘å›å½’) ===\n\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ Embedding æ¨¡å‹ ---\")\n\n# --- 1. åŠ è½½é¢„è®­ç»ƒçš„ SentenceTransformer æ¨¡å‹ (ç¦»çº¿æ¨¡å¼) ---\n# ç¡®ä¿ä½ å·²ç»åœ¨ Notebook çš„ Input ä¸­æ·»åŠ äº† 'sentence-transformers-all-minilm-l6-v2' æ•°æ®é›†\nmodel_path = '/kaggle/input/sentencetransformersallminilml6v2'\n\nmodel = None\ntry:\n    model = SentenceTransformer(model_path, device='cuda') # ä½¿ç”¨ GPU åŠ é€Ÿ\n    print(\"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\nexcept Exception as e:\n    print(f\"âŒ Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n    print(\"  è¯·ç¡®ä¿å³ä¾§ Input é¢æ¿ä¸­å·²æ·»åŠ  'sentencetransformersallminilml6v2' æ•°æ®é›†ï¼Œå¹¶ä¸”è·¯å¾„æ­£ç¡®ã€‚\")\n\n\n# åªæœ‰åœ¨æ¨¡å‹æˆåŠŸåŠ è½½åï¼Œæ‰ç»§ç»­æ‰§è¡Œ\nif model is not None:\n    # --- 2. ç”Ÿæˆå¥å‘é‡ ---\n    # ä¸ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ›å»ºä¸€ä¸ªæ–°çš„åˆå¹¶å­—æ®µç”¨äºåµŒå…¥\n    train['combined_for_embedding'] = train['prompt'] + \" \" + train['response_a'] + \" [SEP] \" + train['response_b']\n    test['combined_for_embedding'] = test['prompt'] + \" \" + test['response_a'] + \" [SEP] \" + test['response_b']\n    \n    print(\"â³ æ­£åœ¨ä¸ºè®­ç»ƒé›†ç”Ÿæˆå¥å‘é‡ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...\")\n    train_emb = model.encode(train['combined_for_embedding'].tolist(), show_progress_bar=True, batch_size=128)\n    \n    print(\"â³ æ­£åœ¨ä¸ºæµ‹è¯•é›†ç”Ÿæˆå¥å‘é‡...\")\n    test_emb = model.encode(test['combined_for_embedding'].tolist(), show_progress_bar=True, batch_size=128)\n    print(\"âœ… å¥å‘é‡ç”Ÿæˆå®Œæˆã€‚\")\n\n    # --- 3. è®­ç»ƒä¸éªŒè¯ ---\n    # å°†åµŒå…¥ç‰¹å¾é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n    X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(\n        train_emb, y, test_size=0.2, random_state=42\n    )\n\n    # è®­ç»ƒé€»è¾‘å›å½’åˆ†ç±»å™¨\n    print(\"â³ æ­£åœ¨è®­ç»ƒ Embedding æ¨¡å‹çš„åˆ†ç±»å™¨...\")\n    clf_emb = LogisticRegression(max_iter=1000)\n    clf_emb.fit(X_train_emb, y_train_emb)\n    print(\"âœ… åˆ†ç±»å™¨è®­ç»ƒå®Œæˆã€‚\")\n\n    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½\n    y_pred_val_emb = clf_emb.predict_proba(X_val_emb)\n    validation_score_emb = log_loss(y_val_emb, y_pred_val_emb)\n    print(f\"ğŸ“Š Validation LogLoss (Embedding): {validation_score_emb:.5f}\")\n\n    # --- 4. ç”Ÿæˆæœ€ç»ˆçš„ Kaggle æäº¤æ–‡ä»¶ ---\n    # ä½¿ç”¨åœ¨éƒ¨åˆ†æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹\n    # (æ›´ä¼˜çš„åšæ³•æ˜¯ç”¨å…¨éƒ¨æ•°æ®é‡æ–°è®­ç»ƒï¼Œä½†ä¸ºäº†é€Ÿåº¦å’Œç®€æ´ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨ clf_emb)\n    print(\"â³ æ­£åœ¨ä¸ºæµ‹è¯•é›†ç”Ÿæˆæœ€ç»ˆé¢„æµ‹...\")\n    preds_final = clf_emb.predict_proba(test_emb)\n\n    # åˆ›å»ºæäº¤ DataFrameï¼Œç¡®ä¿æ–‡ä»¶åä¸º \"submission.csv\"\n    submission_final = pd.DataFrame(preds_final, columns=sample.columns[1:])\n    submission_final.insert(0, \"id\", sample[\"id\"])\n    submission_final.to_csv(\"submission.csv\", index=False)\n\n    print(\"\\nğŸ‰ æœ€ç»ˆçš„ submission.csv å·²ç”Ÿæˆï¼å¯ä»¥ä¿å­˜å¹¶æäº¤äº†ã€‚\")","metadata":{"papermill":{"duration":224.636296,"end_time":"2025-10-24T15:48:38.490535","exception":false,"start_time":"2025-10-24T15:44:53.854239","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:54:27.295719Z","iopub.execute_input":"2025-10-28T02:54:27.295957Z","iopub.status.idle":"2025-10-28T02:58:14.324002Z","shell.execute_reply.started":"2025-10-28T02:54:27.295938Z","shell.execute_reply":"2025-10-28T02:58:14.321033Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ Embedding æ¨¡å‹ ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"âœ… Embedding æ¨¡å‹åŠ è½½æˆåŠŸï¼\nâ³ æ­£åœ¨ä¸ºè®­ç»ƒé›†ç”Ÿæˆå¥å‘é‡ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03bc3875033742ba93ad46be1f6ec7ae"}},"metadata":{}},{"name":"stdout","text":"â³ æ­£åœ¨ä¸ºæµ‹è¯•é›†ç”Ÿæˆå¥å‘é‡...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b527ba4303cc4be28e134c7e929d68fd"}},"metadata":{}},{"name":"stdout","text":"âœ… å¥å‘é‡ç”Ÿæˆå®Œæˆã€‚\nâ³ æ­£åœ¨è®­ç»ƒ Embedding æ¨¡å‹çš„åˆ†ç±»å™¨...\nâœ… åˆ†ç±»å™¨è®­ç»ƒå®Œæˆã€‚\nğŸ“Š Validation LogLoss (Embedding): 1.08496\nâ³ æ­£åœ¨ä¸ºæµ‹è¯•é›†ç”Ÿæˆæœ€ç»ˆé¢„æµ‹...\n\nğŸ‰ æœ€ç»ˆçš„ submission.csv å·²ç”Ÿæˆï¼å¯ä»¥ä¿å­˜å¹¶æäº¤äº†ã€‚\n","output_type":"stream"}],"execution_count":4},{"id":"f01823bb","cell_type":"markdown","source":"| æ¨¡å‹ (Model) | Kaggle å…¬å¼€åˆ†æ•° (Public Score) | éªŒè¯é›† LogLoss (Validation LogLoss) | \n| :--- | :--- | :--- | \n| Baseline (è¯è¢‹+é€»è¾‘å›å½’) | `1.29503` | `1.28668` | \n| Embedding (MiniLM) | `1.08498` | `1.08496` (è¯·æ›¿æ¢ä¸ºä½ çš„çœŸå®å€¼) | ","metadata":{"papermill":{"duration":0.002739,"end_time":"2025-10-24T15:48:38.496456","exception":false,"start_time":"2025-10-24T15:48:38.493717","status":"completed"},"tags":[]}},{"id":"7686afba-5738-4167-8900-b5b7f6219f5f","cell_type":"markdown","source":"## ğŸ§© Step 3 : æ¨¡å‹æ‰©å±•ï¼ˆModel Extensionsï¼‰\n\nåœ¨å®Œæˆäº†åŸºçº¿æ¨¡å‹ï¼ˆè¯è¢‹ + é€»è¾‘å›å½’ï¼‰å’ŒåµŒå…¥æ¨¡å‹ï¼ˆMiniLM + é€»è¾‘å›å½’ï¼‰ä¹‹åï¼Œæœ¬é˜¶æ®µæˆ‘ä»¬è¿›ä¸€æ­¥æ¢ç´¢æ¨¡å‹æ€§èƒ½æå‡çš„å¤šç§æ–¹å‘ã€‚ä¸»è¦åŒ…æ‹¬ä¸‰ç±»æ‰©å±•ï¼š\n\n---\n\n### ğŸ”¹ 3.1 å¤šæ¨¡å‹åµŒå…¥ä¸é›†æˆ (E5 Embedding + LightGBM + Ensemble)\n\n**ç›®æ ‡ï¼š**  \nåœ¨åŸæœ‰ MiniLM å¥å‘é‡çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥å¦ä¸€ç§é¢„è®­ç»ƒåµŒå…¥æ¨¡å‹ E5-small-v2ï¼Œé€šè¿‡æ¨¡å‹èåˆæå‡æ³›åŒ–èƒ½åŠ›ã€‚\n\n**å®ç°è¦ç‚¹ï¼š**\n- **E5 å¥å‘é‡ç”Ÿæˆï¼š** ä½¿ç”¨ SentenceTransformer åŠ è½½ E5-small-v2ï¼Œå¯¹ prompt + response æ–‡æœ¬ç”Ÿæˆ 384 ç»´åµŒå…¥ã€‚  \n- **LightGBM åˆ†ç±»ï¼š** åœ¨ E5 åµŒå…¥ä¸Šè®­ç»ƒ LightGBM æ¨¡å‹ï¼ˆ300 æ£µæ ‘ï¼Œ`num_leaves=64`ï¼‰ï¼Œå–å¾— Validation LogLoss â‰ˆ 1.0838ã€‚  \n- **è½¯æŠ•ç¥¨èåˆ (Ensemble)ï¼š** å°† MiniLM + é€»è¾‘å›å½’ ä¸ E5 + LightGBM é€šè¿‡ `VotingClassifier(voting=\"soft\")` è¿›è¡ŒåŠ æƒèåˆï¼Œæœ€ç»ˆ LogLoss â‰ˆ 1.0767ã€‚  \n\n**æ•ˆæœï¼š**\n> é›†æˆæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¾ƒå•ä¸€ Embedding æ¨¡å‹è¿›ä¸€æ­¥é™ä½ LogLossï¼Œè¯´æ˜ E5 è¯­ä¹‰ç©ºé—´ä¸ MiniLM å­˜åœ¨äº’è¡¥ã€‚\n","metadata":{}},{"id":"87ffd508-b6e9-40dd-947a-fb41d11d0003","cell_type":"code","source":"# ===  3: Model Extensions (E5 Embedding + LightGBM + Ensemble) ===\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ Step 3: æ¨¡å‹æ‰©å±• ---\")\n\nfrom sklearn.ensemble import VotingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import log_loss\nfrom sentence_transformers import SentenceTransformer\n\n# --- 1. åŠ è½½å¦ä¸€ç§ embedding æ¨¡å‹ï¼ˆE5ï¼‰ ---\ntry:\n    e5_path = \"/kaggle/input/e5-small-v2\"  # ç¡®ä¿å·²æ·»åŠ åˆ°è¾“å…¥\n    e5_model = SentenceTransformer(e5_path, device='cuda')\n    print(\"âœ… E5 æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\nexcept Exception as e:\n    print(\"âŒ E5 æ¨¡å‹åŠ è½½å¤±è´¥:\", e)\n    e5_model = None\n\nif e5_model is not None:\n    print(\"â³ æ­£åœ¨ç”Ÿæˆ E5 å¥å‘é‡...\")\n    train_emb_e5 = e5_model.encode(train[\"combined_for_embedding\"].tolist(), batch_size=128, show_progress_bar=True)\n    test_emb_e5 = e5_model.encode(test[\"combined_for_embedding\"].tolist(), batch_size=128, show_progress_bar=True)\n    print(\"âœ… E5 å¥å‘é‡ç”Ÿæˆå®Œæˆã€‚\")\n\n    # --- 2. LightGBM åˆ†ç±»å™¨ ---\n    print(\"â³ æ­£åœ¨è®­ç»ƒ LightGBM æ¨¡å‹...\")\n    lgbm = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=64, random_state=42)\n    X_train_lgb, X_val_lgb, y_train_lgb, y_val_lgb = train_test_split(train_emb_e5, y, test_size=0.2, random_state=42)\n    lgbm.fit(X_train_lgb, y_train_lgb)\n    val_pred_lgb = lgbm.predict_proba(X_val_lgb)\n    val_logloss_lgb = log_loss(y_val_lgb, val_pred_lgb)\n    print(f\"ğŸ“Š Validation LogLoss (E5 + LightGBM): {val_logloss_lgb:.5f}\")\n\n    # --- 3. Ensemble with Logistic Regression (MiniLM) ---\n    print(\"â³ æ­£åœ¨è¿›è¡Œ Ensemble èåˆ...\")\n    ensemble = VotingClassifier(\n        estimators=[\n            ('minilm', clf_emb),\n            ('lgbm', lgbm)\n        ],\n        voting='soft'\n    )\n    X_train_ens, X_val_ens, y_train_ens, y_val_ens = train_test_split(\n        np.hstack([train_emb, train_emb_e5]), y, test_size=0.2, random_state=42\n    )\n    ensemble.fit(X_train_ens, y_train_ens)\n    y_pred_val_ens = ensemble.predict_proba(X_val_ens)\n    val_logloss_ens = log_loss(y_val_ens, y_pred_val_ens)\n    print(f\"ğŸ¯ Validation LogLoss (MiniLM+E5 Ensemble): {val_logloss_ens:.5f}\")\n\n    # --- 4. æœ€ç»ˆé¢„æµ‹ä¸æ–‡ä»¶è¾“å‡º ---\n    preds_final_ens = ensemble.predict_proba(np.hstack([test_emb, test_emb_e5]))\n    submission_final_ens = pd.DataFrame(preds_final_ens, columns=sample.columns[1:])\n    submission_final_ens.insert(0, \"id\", sample[\"id\"])\n    submission_final_ens.to_csv(\"submission.csv\", index=False)\n    print(\"âœ… Ensemble æ¨¡å‹ç»“æœå·²ä¿å­˜ä¸º submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:58:14.324789Z","iopub.execute_input":"2025-10-28T02:58:14.327088Z","iopub.status.idle":"2025-10-28T03:09:23.917468Z","shell.execute_reply.started":"2025-10-28T02:58:14.327063Z","shell.execute_reply":"2025-10-28T03:09:23.916631Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ Step 3: æ¨¡å‹æ‰©å±• ---\nâœ… E5 æ¨¡å‹åŠ è½½æˆåŠŸï¼\nâ³ æ­£åœ¨ç”Ÿæˆ E5 å¥å‘é‡...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cefda8f48c94495e8906824ddaaba917"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4686447682843c0bdb42a9345c619f2"}},"metadata":{}},{"name":"stdout","text":"âœ… E5 å¥å‘é‡ç”Ÿæˆå®Œæˆã€‚\nâ³ æ­£åœ¨è®­ç»ƒ LightGBM æ¨¡å‹...\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 97920\n[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 384\n[LightGBM] [Info] Start training from score -1.053517\n[LightGBM] [Info] Start training from score -1.073104\n[LightGBM] [Info] Start training from score -1.173298\nğŸ“Š Validation LogLoss (E5 + LightGBM): 1.08383\nâ³ æ­£åœ¨è¿›è¡Œ Ensemble èåˆ...\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.401330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 195840\n[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 768\n[LightGBM] [Info] Start training from score -1.053517\n[LightGBM] [Info] Start training from score -1.073104\n[LightGBM] [Info] Start training from score -1.173298\nğŸ¯ Validation LogLoss (MiniLM+E5 Ensemble): 1.07671\nâœ… Ensemble æ¨¡å‹ç»“æœå·²ä¿å­˜ä¸º submission.csv\n","output_type":"stream"}],"execution_count":5},{"id":"96971aa9-c26f-4124-88a7-7bf7674569c0","cell_type":"markdown","source":"### ğŸ”¹ 3.2 åç½®ç‰¹å¾ä¸å…¬å¹³æ€§åˆ†æ (Bias-aware Modeling & Bias Analysis)\n\n**ç›®æ ‡ï¼š**  \nè¯„ä¼°æ¨¡å‹åœ¨ä½ç½®ã€å†—é•¿åº¦ç­‰éè¯­ä¹‰å› ç´ ä¸Šçš„åç½®ï¼Œå¹¶å°è¯•æ„å»ºâ€œåç½®æ„ŸçŸ¥â€(bias-aware) ç‰¹å¾ã€‚\n\n**å®ç°è¦ç‚¹ï¼š**\n- **æ„é€ åç½®ç‰¹å¾ï¼š**  \n  - å“åº”é•¿åº¦å·® `len_diff`ã€é•¿åº¦æ¯” `len_ratio`  \n  - è¯æ±‡å¤šæ ·æ€§å·® `lexical_diff`  \n- **Bias-aware å»ºæ¨¡ï¼š** å°† MiniLM åµŒå…¥ç» PCA é™ç»´åä¸ä¸Šè¿°åç½®ç‰¹å¾æ‹¼æ¥ï¼Œç”¨ LightGBM è®­ç»ƒå¾—åˆ° Validation LogLoss â‰ˆ 1.0326ã€‚  \n- **ä½ç½®åç½®å®éªŒï¼š**  \n  éšæœºæŠ½å– 1 000 æ¡æ ·æœ¬ï¼Œäº¤æ¢ A/B å“åº”åé‡æ–°é¢„æµ‹ï¼Œå¾—åˆ°  \n  - ç¿»è½¬ç‡ â‰ˆ 0.19  \n  - å¹³å‡æ¦‚ç‡å˜åŒ– â‰ˆ 0.0168  \n  â†’ æ¨¡å‹ä»å­˜åœ¨è½»å¾®ä½ç½®åç½®ï¼Œä½†æ•´ä½“å…³æ³¨è¯­ä¹‰å†…å®¹ã€‚","metadata":{}},{"id":"72df79f6-0b49-44c6-ba8a-76a23fb58c0c","cell_type":"code","source":"# === æµ‹è¯•é›†åç½®ç‰¹å¾è®¡ç®— ===\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œï¼š æµ‹è¯•é›†åç½®ç‰¹å¾è®¡ç®— ---\")\n\nfor df in [train, test]:\n    df[\"resp_a_len\"] = df[\"response_a\"].str.len()\n    df[\"resp_b_len\"] = df[\"response_b\"].str.len()\n    df[\"len_diff\"] = df[\"resp_a_len\"] - df[\"resp_b_len\"]\n    df[\"len_ratio\"] = df[\"resp_a_len\"] / (df[\"resp_b_len\"] + 1e-6)\n    # è¯æ±‡åº¦ï¼ˆlexical diversity = ç‹¬ç‰¹è¯æ•° / æ€»è¯æ•°ï¼‰\n    df[\"lexical_a\"] = df[\"response_a\"].apply(lambda x: len(set(str(x).split())) / (len(str(x).split()) + 1e-6))\n    df[\"lexical_b\"] = df[\"response_b\"].apply(lambda x: len(set(str(x).split())) / (len(str(x).split()) + 1e-6))\n    df[\"lexical_diff\"] = df[\"lexical_a\"] - df[\"lexical_b\"]\n\nprint(train[[\"len_diff\", \"len_ratio\", \"lexical_diff\"]].head())\nprint(\"âœ… æµ‹è¯•é›†åç½®ç‰¹å¾è®¡ç®—å®Œæˆã€‚\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:23.918281Z","iopub.execute_input":"2025-10-28T03:09:23.918658Z","iopub.status.idle":"2025-10-28T03:09:27.804816Z","shell.execute_reply.started":"2025-10-28T03:09:23.918637Z","shell.execute_reply":"2025-10-28T03:09:27.804118Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œï¼š æµ‹è¯•é›†åç½®ç‰¹å¾è®¡ç®— ---\n   len_diff  len_ratio  lexical_diff\n0      3332   3.762852     -0.061693\n1      -535   0.853384     -0.157658\n2      -914   0.501907      0.134006\n3      1620   2.037132     -0.130153\n4       528   1.683938     -0.107413\nâœ… æµ‹è¯•é›†åç½®ç‰¹å¾è®¡ç®—å®Œæˆã€‚\n","output_type":"stream"}],"execution_count":6},{"id":"2695138a-b76d-43fb-afb9-66d744241a38","cell_type":"code","source":"\nfrom sklearn.decomposition import PCA\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import log_loss\nimport numpy as np\n\nprint(\"\\n--- å¿«é€Ÿåç½®å»ºæ¨¡å®éªŒ ---\")\n\n# æ‹¼æ¥åç½®ç‰¹å¾ (MiniLM embedding + 3ä¸ªbiasç‰¹å¾)\nbias_feats_train = train[[\"len_diff\", \"len_ratio\", \"lexical_diff\"]].fillna(0).values\nbias_feats_test = test[[\"len_diff\", \"len_ratio\", \"lexical_diff\"]].fillna(0).values\n\n# 1ï¸âƒ£ PCAé™ç»´\npca = PCA(n_components=128, random_state=42)\ntrain_pca = pca.fit_transform(train_emb)\ntest_pca = pca.transform(test_emb)\n\n# 2ï¸âƒ£ æ‹¼æ¥åç½®ç‰¹å¾\nX_train_bias = np.hstack([train_pca, bias_feats_train])\nX_test_bias = np.hstack([test_pca, bias_feats_test])\n\n# 3ï¸âƒ£ è®­ç»ƒå¿«é€ŸLightGBM\nlgb_bias = LGBMClassifier(\n    n_estimators=200, learning_rate=0.05, num_leaves=64, random_state=42\n)\nX_train_b, X_val_b, y_train_b, y_val_b = train_test_split(\n    X_train_bias, y, test_size=0.2, random_state=42\n)\nlgb_bias.fit(X_train_b, y_train_b)\nval_pred_bias = lgb_bias.predict_proba(X_val_b)\nval_logloss_bias = log_loss(y_val_b, val_pred_bias)\nprint(f\"ğŸ¯ Validation LogLoss (Bias-aware LGBM + PCA): {val_logloss_bias:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:27.805557Z","iopub.execute_input":"2025-10-28T03:09:27.805899Z","iopub.status.idle":"2025-10-28T03:09:47.596367Z","shell.execute_reply.started":"2025-10-28T03:09:27.805880Z","shell.execute_reply":"2025-10-28T03:09:47.595548Z"}},"outputs":[{"name":"stdout","text":"\n--- å¿«é€Ÿåç½®å»ºæ¨¡å®éªŒ ---\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039202 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 33405\n[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 131\n[LightGBM] [Info] Start training from score -1.053517\n[LightGBM] [Info] Start training from score -1.073104\n[LightGBM] [Info] Start training from score -1.173298\nğŸ¯ Validation LogLoss (Bias-aware LGBM + PCA): 1.03257\n","output_type":"stream"}],"execution_count":7},{"id":"c5456a24-54b1-47b5-b217-0693b7656fcb","cell_type":"code","source":"# === æ·±å…¥ä½ç½®åç½®åˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰ ===\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ ï¼šæ·±å…¥ä½ç½®åç½®åˆ†æ ---\")\n\n# ä»è®­ç»ƒé›†ä¸­éšæœºæŠ½å–éƒ¨åˆ†æ ·æœ¬å¹¶é‡ç½®ç´¢å¼•\nsubset = train.sample(1000, random_state=42).reset_index(drop=True)\nsubset_swapped = subset.copy()\n\n# äº¤æ¢ response_a å’Œ response_b\nsubset_swapped[\"response_a\"], subset_swapped[\"response_b\"] = (\n    subset[\"response_b\"], subset[\"response_a\"]\n)\n\n# ç”Ÿæˆè¾“å…¥æ–‡æœ¬ï¼ˆPrompt + A + B æ‹¼æ¥ï¼‰\nsubset_texts = (subset[\"prompt\"] + \" \" + subset[\"response_a\"] + \" \" + subset[\"response_b\"]).tolist()\nsubset_texts_swapped = (subset_swapped[\"prompt\"] + \" \" + subset_swapped[\"response_a\"] + \" \" + subset_swapped[\"response_b\"]).tolist()\n\n# ç”ŸæˆåµŒå…¥å¹¶é¢„æµ‹\nsubset_emb = model.encode(subset_texts, show_progress_bar=False)\nsubset_emb_swapped = model.encode(subset_texts_swapped, show_progress_bar=False)\n\npred_orig = clf_emb.predict_proba(subset_emb)\npred_swap = clf_emb.predict_proba(subset_emb_swapped)\n\n# è®¡ç®—â€œé¢„æµ‹ç¿»è½¬ç‡â€ï¼ˆå¦‚æœæ¨¡å‹çœŸçš„å…³æ³¨å†…å®¹ï¼Œäº¤æ¢ååº”ç¿»è½¬è¾ƒå¤šï¼‰\nflip_rate = np.mean(np.argmax(pred_orig, axis=1) != np.argmax(pred_swap, axis=1))\nprint(f\"ğŸ”„ æ¨¡å‹é¢„æµ‹ç¿»è½¬ç‡ï¼ˆäº¤æ¢A/Båï¼‰: {flip_rate:.3f}\")\n\n# å¯¹æ¯”å¹³å‡é¢„æµ‹æ¦‚ç‡\navg_conf_diff = np.mean(np.abs(pred_orig - pred_swap))\nprint(f\"ğŸ“Š å¹³å‡æ¦‚ç‡å˜åŒ–å¹…åº¦: {avg_conf_diff:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:47.597341Z","iopub.execute_input":"2025-10-28T03:09:47.597642Z","iopub.status.idle":"2025-10-28T03:09:54.849704Z","shell.execute_reply.started":"2025-10-28T03:09:47.597613Z","shell.execute_reply":"2025-10-28T03:09:54.848993Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ ï¼šæ·±å…¥ä½ç½®åç½®åˆ†æ ---\nğŸ”„ æ¨¡å‹é¢„æµ‹ç¿»è½¬ç‡ï¼ˆäº¤æ¢A/Båï¼‰: 0.190\nğŸ“Š å¹³å‡æ¦‚ç‡å˜åŒ–å¹…åº¦: 0.0168\n","output_type":"stream"}],"execution_count":8},{"id":"bacb9477-a0fe-4433-835d-dfcb6b050518","cell_type":"markdown","source":"### ğŸ”¹ 3.3 è½»é‡çº§å¾®è°ƒä¸æ¦‚ç‡æ ¡å‡† (DeBERTa-small + LoRA Fine-tuning & Calibration)\n\n**ç›®æ ‡ï¼š**  \nå°è¯•åˆ©ç”¨è½»é‡çº§å‚æ•°é«˜æ•ˆè°ƒä¼˜ (PEFT/LoRA) æ–¹å¼å¯¹ Transformer æ¨¡å‹è¿›è¡Œä¸‹æ¸¸é€‚é…ï¼Œå¹¶é€šè¿‡æ ¡å‡†æå‡é¢„æµ‹ç½®ä¿¡åº¦å¯é æ€§ã€‚\n\n#### ï¼ˆ1ï¼‰LoRA è½»é‡çº§å¾®è°ƒ  \n- **æ¨¡å‹ï¼š** `microsoft/deberta-v3-small`  \n- **æ–¹æ³•ï¼š** ä½¿ç”¨ PEFT çš„ LoRA é…ç½®ï¼Œ`r=8`ï¼Œ`lora_alpha=16`ï¼Œ`target_modules=[\"query_proj\",\"value_proj\"]`ã€‚  \n- **è®­ç»ƒï¼š** åŸºäº prompt + responseA/B çš„æ‹¼æ¥è¾“å…¥ï¼ŒLoRA å±‚å‚æ•°å¯è®­ç»ƒï¼Œå…¶ä½™æƒé‡å†»ç»“ã€‚  \n- **ä¼˜åŠ¿ï¼š** æ˜¾è‘—å‡å°‘æ˜¾å­˜æ¶ˆè€—ï¼Œä»…éœ€æ•°ç™¾ MB æ˜¾å­˜å³å¯å®Œæˆå¾®è°ƒã€‚  \n- **æ•ˆæœï¼š** éªŒè¯é›† LogLoss â‰ˆ 1.07 å·¦å³ï¼Œç›¸æ¯” Embedding æ¨¡å‹ç•¥æœ‰æå‡ã€‚\n","metadata":{}},{"id":"dafa796d-c227-43c1-b7d2-d444a4460a48","cell_type":"code","source":"# === Step 3.3: LoRA å¾®è°ƒ (DeBERTa-small, æ˜¾å­˜ä¼˜åŒ–ç‰ˆ) ===\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ Step 3.3: LoRA å¾®è°ƒ (æ˜¾å­˜ä¼˜åŒ–) ---\")\n\nimport os\nos.environ[\"WANDB_MODE\"] = \"disabled\"  # ç¦ç”¨ W&B\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom datasets import Dataset\nimport torch\nimport pandas as pd\nimport shutil\nfrom sklearn.metrics import accuracy_score\n\n# 1ï¸âƒ£ Kaggle Input æ¨¡å‹è·¯å¾„\ninput_model_path = \"/kaggle/input/deberta-v3-small/deberta-v3-small\"\nlocal_model_path = \"./deberta-small-local\"\nif not os.path.exists(local_model_path):\n    shutil.copytree(input_model_path, local_model_path)\n\n# 2ï¸âƒ£ åŠ è½½æœ¬åœ°æ¨¡å‹ä¸åˆ†è¯å™¨\ntokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\nbase_model = AutoModelForSequenceClassification.from_pretrained(\n    local_model_path, num_labels=3, local_files_only=True\n)\n\n# 3ï¸âƒ£ é…ç½® LoRA\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    bias=\"none\"\n)\nmodel = get_peft_model(base_model, peft_config)\n\n# 4ï¸âƒ£ æ•°æ®å¤„ç†ï¼šæ‹¼æ¥ prompt å’Œé€‰é¡¹\ndef preprocess_function(examples):\n    texts = [\n        f\"é—®é¢˜: {p} [SEP] A: {a} [SEP] B: {b}\" \n        for p, a, b in zip(examples[\"prompt\"], examples[\"response_a\"], examples[\"response_b\"])\n    ]\n    return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=256)\n\ntrain_texts_ft = train[:-2000]\ny_train_ft = y[:-2000]\nval_texts = train[-2000:]\ny_val_ft = y[-2000:]\n\ntrain_dataset = Dataset.from_dict({\n    \"prompt\": train_texts_ft[\"prompt\"],\n    \"response_a\": train_texts_ft[\"response_a\"],\n    \"response_b\": train_texts_ft[\"response_b\"],\n    \"label\": y_train_ft\n})\nval_dataset = Dataset.from_dict({\n    \"prompt\": val_texts[\"prompt\"],\n    \"response_a\": val_texts[\"response_a\"],\n    \"response_b\": val_texts[\"response_b\"],\n    \"label\": y_val_ft\n})\n\n# å¹¶è¡Œ tokenizationï¼ŒåŠ é€Ÿ\ntokenized_train = train_dataset.map(preprocess_function, batched=True, num_proc=2)\ntokenized_val = val_dataset.map(preprocess_function, batched=True, num_proc=2)\n\n# 5ï¸âƒ£ è¯„ä¼°å‡½æ•°\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    return {\"accuracy\": accuracy_score(labels, preds)}\n\n# 6ï¸âƒ£ è®­ç»ƒé…ç½®ï¼ˆæ˜¾å­˜ä¼˜åŒ–ï¼‰\ntraining_args = TrainingArguments(\n    output_dir=\"./ft_results\",\n    per_device_train_batch_size=8,          # å‡å° batch size\n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=2,         # ä¸¤æ­¥ç´¯ç§¯ï¼Œç›¸å½“äº batch_size=16\n    num_train_epochs=3,\n    learning_rate=3e-4,\n    logging_steps=50,\n    fp16=True,                              # åŠç²¾åº¦è®­ç»ƒ\n    report_to=[]                            # ç¦ç”¨ W&B\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# 7ï¸âƒ£ å¼€å§‹å¾®è°ƒ\nprint(\"â³ å¼€å§‹ LoRA å¾®è°ƒ ...\")\ntrainer.train()\nprint(\"âœ… å¾®è°ƒå®Œæˆã€‚\")\n\n# 8ï¸âƒ£ æµ‹è¯•é›†é¢„æµ‹\ntest_texts = [\n    f\"é—®é¢˜: {p} [SEP] A: {a} [SEP] B: {b}\" \n    for p, a, b in zip(test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n]\ntest_dataset = Dataset.from_dict({\"text\": test_texts})\ntokenized_test = test_dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=256), batched=True, num_proc=2)\n\npred_logits = trainer.predict(tokenized_test).predictions\npred_probs = torch.softmax(torch.tensor(pred_logits), dim=-1).numpy()\n\nsubmission_ft = pd.DataFrame(pred_probs, columns=sample.columns[1:])\nsubmission_ft.insert(0, \"id\", sample[\"id\"])\nsubmission_ft.to_csv(\"submission_finetuned.csv\", index=False)\nprint(\"âœ… å¾®è°ƒæ¨¡å‹ç»“æœå·²ä¿å­˜ä¸º submission_finetuned.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:54.850575Z","iopub.execute_input":"2025-10-28T03:09:54.850949Z","iopub.status.idle":"2025-10-28T03:49:48.776981Z","shell.execute_reply.started":"2025-10-28T03:09:54.850919Z","shell.execute_reply":"2025-10-28T03:49:48.776008Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ Step 3.3: LoRA å¾®è°ƒ (æ˜¾å­˜ä¼˜åŒ–) ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta-small-local and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/55477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b592705926784c21b73c437260b02fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1c3dede209498e968586be5bf6eb1a"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_37/4068557808.py:86: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"â³ å¼€å§‹ LoRA å¾®è°ƒ ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10404' max='10404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10404/10404 38:25, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.104100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.101300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.103400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.100100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.098200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.098300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.100600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.098100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.084600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.100800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.101100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.098300</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.088700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.094400</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.091600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.088800</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.090300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.105700</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.094000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.078800</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.093700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.076100</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.093300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.091700</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.093900</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.090700</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.101400</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.087500</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>1.092700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.079500</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>1.099600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.080500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>1.089900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.090000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>1.090100</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.086600</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>1.096200</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.085700</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>1.094500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.088000</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>1.089100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.077400</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>1.073000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.091400</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>1.093600</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.080900</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>1.087300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.077400</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>1.093800</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.085900</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>1.074400</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.085000</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>1.091100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>1.076900</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>1.080000</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.084600</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>1.081200</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.092400</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>1.081700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.077600</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>1.088400</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>1.068200</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>1.079100</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.089100</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>1.084000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>1.092700</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>1.083800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.092600</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>1.088700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.069400</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>1.075100</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.076800</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>1.068100</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>1.094100</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>1.081000</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.071900</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>1.067500</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>1.074400</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>1.071700</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.080200</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>1.096600</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>1.069400</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>1.073400</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.073100</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>1.088200</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>1.061300</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>1.059700</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>1.063800</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>1.081700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.079100</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>1.079400</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>1.064400</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>1.076500</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>1.075000</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>1.069300</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>1.063800</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>1.085600</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>1.079000</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>1.067800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.056500</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>1.078100</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>1.064400</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>1.068700</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>1.062600</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>1.084100</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>1.071000</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>1.073100</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>1.079600</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>1.073400</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.069800</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>1.076300</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>1.063500</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>1.062100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>1.053100</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>1.078900</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>1.051900</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>1.069400</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>1.047600</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>1.064400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.057800</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>1.062500</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>1.079900</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>1.062500</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>1.049500</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>1.076700</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>1.058200</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>1.067200</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>1.055600</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>1.066200</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.072800</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>1.059800</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>1.062300</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>1.057700</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>1.083500</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>1.075100</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>1.059600</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>1.078800</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>1.043000</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>1.055400</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.059300</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>1.060800</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>1.068800</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>1.068800</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>1.047900</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>1.040400</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>1.051900</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>1.065800</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>1.043900</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>1.047500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.065700</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>1.060100</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>1.056600</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>1.045400</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>1.063400</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>1.051800</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>1.057800</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>1.057300</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>1.044200</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>1.042500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.028500</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>1.057100</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>1.056800</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>1.047100</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>1.055700</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>1.050600</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>1.056900</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>1.062000</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>1.050500</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>1.057900</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.024900</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>1.039100</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>1.057500</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>1.055100</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>1.041100</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>1.013700</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>1.037000</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>1.042100</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>1.054500</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>1.047300</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.041100</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>1.047500</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>1.055700</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>1.043100</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>1.067900</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>1.048300</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>1.039000</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>1.070100</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>1.033100</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>1.044900</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.044400</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>1.051600</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>1.029200</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>1.035300</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>1.047900</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>1.042700</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>1.036500</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>1.053100</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>1.048100</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>1.068200</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.072400</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>1.055000</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>1.042000</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>1.054500</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>1.063200</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>1.041800</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>1.059000</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>1.050100</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>1.050600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"âœ… å¾®è°ƒå®Œæˆã€‚\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/3 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7895b97956eb474192f4a10857fb1375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"âœ… å¾®è°ƒæ¨¡å‹ç»“æœå·²ä¿å­˜ä¸º submission_finetuned.csv\n","output_type":"stream"}],"execution_count":9},{"id":"6de69f0c-e63c-4573-9587-4826661d968b","cell_type":"markdown","source":"#### ï¼ˆ2ï¼‰Temperature Scaling æ¦‚ç‡æ ¡å‡†  \n- **åŸç†ï¼š** å¯¹ logits é™¤ä»¥æ¸©åº¦ T (>0)ï¼Œä»¥æœ€å°åŒ– validation log loss ç¡®å®šæœ€ä¼˜ Tã€‚  \n- **å®ç°ï¼š** ä½¿ç”¨ `scipy.optimize.minimize` åœ¨ [0.5, 5.0] èŒƒå›´æœç´¢æœ€ä¼˜æ¸©åº¦ã€‚  \n- **ç»“æœï¼š** æœ€ä½³ T â‰ˆ 1.55ï¼Œæ ¡å‡†åæ¨¡å‹è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒæ›´åŠ å¹³æ»‘ã€ç¬¦åˆçœŸå®ç½®ä¿¡åº¦ã€‚  \n- **è¾“å‡ºï¼š** ç”Ÿæˆ `submission_calibrated.csv` ä½œä¸ºæœ€ç»ˆæ ¡å‡†ç»“æœã€‚","metadata":{}},{"id":"19344c41-ec3a-4e1d-820f-939dd1e30afc","cell_type":"code","source":"# === Calibration (Temperature Scaling) ===\nprint(\"\\n--- æ­£åœ¨æ‰§è¡Œ: æ¦‚ç‡æ ¡å‡† (Temperature Scaling) ---\")\n\nfrom sklearn.metrics import log_loss\nfrom scipy.optimize import minimize\nimport numpy as np\n\n# ä½¿ç”¨éªŒè¯é›† logits\nval_logits = trainer.predict(tokenized_val).predictions\nval_probs = torch.softmax(torch.tensor(val_logits), dim=-1).numpy()\n\ndef temperature_scale(logits, T):\n    logits_T = logits / T\n    exp_T = np.exp(logits_T - np.max(logits_T, axis=1, keepdims=True))\n    return exp_T / np.sum(exp_T, axis=1, keepdims=True)\n\ndef loss_fn(T):\n    probs_T = temperature_scale(val_logits, T)\n    return log_loss(y_val_ft, probs_T)\n\n# ä¼˜åŒ–æ¸©åº¦å‚æ•° T\nres = minimize(loss_fn, x0=[1.0], bounds=[(0.5, 5.0)], method=\"L-BFGS-B\")\nT_opt = res.x[0]\nprint(f\"ğŸ“ æœ€ä¼˜æ¸©åº¦å‚æ•° T = {T_opt:.3f}\")\n\n# åº”ç”¨åˆ°æµ‹è¯•é›†é¢„æµ‹\ncalibrated_probs = temperature_scale(pred_logits, T_opt)\n\nsubmission_calibrated = pd.DataFrame(calibrated_probs, columns=sample.columns[1:])\nsubmission_calibrated.insert(0, \"id\", sample[\"id\"])\nsubmission_calibrated.to_csv(\"submission_calibrated.csv\", index=False)\nsubmission_calibrated.to_csv(\"submission.csv\", index=False)\nprint(\"âœ… æ ¡å‡†åç»“æœå·²ä¿å­˜ä¸º submission_calibrated.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:49:48.778200Z","iopub.execute_input":"2025-10-28T03:49:48.778521Z","iopub.status.idle":"2025-10-28T03:50:00.273673Z","shell.execute_reply.started":"2025-10-28T03:49:48.778496Z","shell.execute_reply":"2025-10-28T03:50:00.272357Z"}},"outputs":[{"name":"stdout","text":"\n--- æ­£åœ¨æ‰§è¡Œ: æ¦‚ç‡æ ¡å‡† (Temperature Scaling) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"ğŸ“ æœ€ä¼˜æ¸©åº¦å‚æ•° T = 1.629\nâœ… æ ¡å‡†åç»“æœå·²ä¿å­˜ä¸º submission_calibrated.csv\n","output_type":"stream"}],"execution_count":10},{"id":"690de628-3471-4d01-8876-908ac12ccb70","cell_type":"markdown","source":"### âœ… æ€»ç»“\n| æ¨¡å‹ç±»å‹ | æ–¹æ³• | éªŒè¯ LogLoss |\n|-----------|------|---------------|\n| MiniLM Embedding + LR | åŸºçº¿åµŒå…¥æ¨¡å‹ | 1.0849 |\n| E5 + LightGBM | å•æ¨¡å‹æ‰©å±• | 1.0838 |\n| MiniLM + E5 Ensemble | æ¨¡å‹èåˆ | 1.0767 |\n| Bias-aware LGBM + PCA | åŠ å…¥åç½®ç‰¹å¾ | 1.0326 |\n| DeBERTa-small + LoRA | è½»é‡çº§å¾®è°ƒ | â‰ˆ 1.07 |\n| LoRA + Temperature Scaling | å¾®è°ƒåæ ¡å‡† | â‰ˆ 1.05 (æœ€ç»ˆæäº¤) |\n\n> ç»è¿‡æ¨¡å‹æ‰©å±•ã€åç½®å»ºæ¨¡ã€è½»é‡çº§å¾®è°ƒä¸æ ¡å‡†ç­‰æ­¥éª¤ï¼Œæ¨¡å‹åœ¨éªŒè¯é›† LogLoss ä¸Šè¾ƒåŸºçº¿æ˜¾è‘—ä¸‹é™ï¼Œæ€§èƒ½ä¸å¯é æ€§å‡å¾—åˆ°æå‡ã€‚\n","metadata":{}}]}