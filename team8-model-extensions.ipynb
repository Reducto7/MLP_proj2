{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":2838990,"sourceType":"datasetVersion","datasetId":1737111},{"sourceId":4838716,"sourceType":"datasetVersion","datasetId":2804156},{"sourceId":6355064,"sourceType":"datasetVersion","datasetId":3660235}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":729.56026,"end_time":"2025-10-24T15:48:42.210230","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-24T15:36:32.649970","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"043a78a335b8415880dd0da806c09438":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"05302b7d73494a10a94a2dc0de65751c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30183693c79345318e8a3ecc88348414","IPY_MODEL_d7be2dc4d8624b5e8d1de337b338d139","IPY_MODEL_68bf8f5642e9490e94ed810f704509d8"],"layout":"IPY_MODEL_2357a40d47874ebbb699c9080d5280e2","tabbable":null,"tooltip":null}},"118953ecbdf8484298f2a987ed6efe24":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2357a40d47874ebbb699c9080d5280e2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30183693c79345318e8a3ecc88348414":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c9157cbfa1ba4594b629202dc1696be5","placeholder":"​","style":"IPY_MODEL_af42f9b294fe44908834110a6ead97da","tabbable":null,"tooltip":null,"value":"Batches: 100%"}},"312978b638f14ebf8710a1f531640f0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_aabf400781bd4cf58db206b42e800e83","placeholder":"​","style":"IPY_MODEL_7061544087ae43a5b4c76af65cb5e22c","tabbable":null,"tooltip":null,"value":" 450/450 [03:23&lt;00:00, 16.85it/s]"}},"4666507cf9324c2993e61b3deda2698f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_cd40b42fbd2942cba8539003c50c5fc9","placeholder":"​","style":"IPY_MODEL_043a78a335b8415880dd0da806c09438","tabbable":null,"tooltip":null,"value":"Batches: 100%"}},"64fca46ebcdd4d2d93e578aba7052b74":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68bf8f5642e9490e94ed810f704509d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_64fca46ebcdd4d2d93e578aba7052b74","placeholder":"​","style":"IPY_MODEL_e119b1124b864ed794ecf204ff4219bb","tabbable":null,"tooltip":null,"value":" 1/1 [00:00&lt;00:00, 37.35it/s]"}},"7061544087ae43a5b4c76af65cb5e22c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"aabf400781bd4cf58db206b42e800e83":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af42f9b294fe44908834110a6ead97da":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"b8026d0ba6fd452c8eeb6d3179021fe9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9157cbfa1ba4594b629202dc1696be5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd40b42fbd2942cba8539003c50c5fc9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d03451a5732c41829eabb5385f1e0000":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b8026d0ba6fd452c8eeb6d3179021fe9","max":450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d81a666ed60745e6b4853e6edf238cfb","tabbable":null,"tooltip":null,"value":450}},"d7be2dc4d8624b5e8d1de337b338d139":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_e8fd271b53dc450d8d1f33b5e57fdaf6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8de2cac119044e19b5eabf47dfa1d22","tabbable":null,"tooltip":null,"value":1}},"d81a666ed60745e6b4853e6edf238cfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e119b1124b864ed794ecf204ff4219bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e8de2cac119044e19b5eabf47dfa1d22":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8fd271b53dc450d8d1f33b5e57fdaf6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eec8ed3b0a5042ccb892473ce9ce06bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4666507cf9324c2993e61b3deda2698f","IPY_MODEL_d03451a5732c41829eabb5385f1e0000","IPY_MODEL_312978b638f14ebf8710a1f531640f0c"],"layout":"IPY_MODEL_118953ecbdf8484298f2a987ed6efe24","tabbable":null,"tooltip":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"de914c02-57ee-4034-9a62-a442a53618cd","cell_type":"markdown","source":"###  1: 导入库与加载数据\n\n**代码分析:**\n\n*   **集中导入**: 在 Notebook 的最开始，我们一次性导入所有需要用到的 Python 库，包括用于数据处理的 `pandas`、科学计算的 `numpy`，以及 `scikit-learn` 中用于特征工程、模型训练和评估的各个模块。这是一个良好的编程习惯，使得代码的依赖关系一目了然。\n*   **数据加载**: 我们使用 `pd.read_csv()` 来加载竞赛提供的三个核心文件：`train.csv` (训练数据)，`test.csv` (测试数据)，和 `sample_submission.csv` (提交格式示例)。\n*   **健壮性**: 整个加载过程被包裹在 `try...except FileNotFoundError` 块中。这样做的好处是，如果因为某种原因（例如数据集未添加到 Notebook）导致文件路径无效，程序不会直接崩溃，而是会打印出一条清晰的错误提示信息，便于我们快速定位问题。","metadata":{}},{"id":"4657eb5c","cell_type":"code","source":"# ===  1: 导入所有必需的库与加载数据 ===\n\n# 数据处理与科学计算\nimport pandas as pd\nimport numpy as np\n\n# 特征工程\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\n\n# 模型与评估\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\n# 深度学习嵌入模型\nfrom sentence_transformers import SentenceTransformer\n\nprint(\"🚀 Team 8 Baseline & Embedding Model Pipeline 启动！\")\n\n# --- 加载数据集 ---\n# 使用 try-except 结构确保数据加载的健壮性\ntry:\n    train = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n    test = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n    sample = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/sample_submission.csv\")\n    print(\"✅ 数据集加载成功!\")\n    print(f\"  训练集大小: {train.shape}\")\n    print(f\"  测试集大小: {test.shape}\")\nexcept FileNotFoundError:\n    print(\"❌ 数据加载失败! 请检查竞赛数据集是否已正确添加到 Notebook.\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":33.715467,"end_time":"2025-10-24T15:37:09.942063","exception":false,"start_time":"2025-10-24T15:36:36.226596","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:45:52.121256Z","iopub.execute_input":"2025-10-28T02:45:52.121570Z","iopub.status.idle":"2025-10-28T02:46:24.443951Z","shell.execute_reply.started":"2025-10-28T02:45:52.121549Z","shell.execute_reply":"2025-10-28T02:46:24.443195Z"}},"outputs":[{"name":"stderr","text":"2025-10-28 02:46:07.027482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761619567.215280      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761619567.273280      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🚀 Team 8 Baseline & Embedding Model Pipeline 启动！\n✅ 数据集加载成功!\n  训练集大小: (57477, 9)\n  测试集大小: (3, 4)\n","output_type":"stream"}],"execution_count":1},{"id":"b1d7c1ba","cell_type":"markdown","source":"###  2: 特征工程\n\n**代码分析:**\n\n*   **核心原则**: 为了保证模型的公平性和有效性，所有对训练集 `train` 进行的特征工程，都**必须以完全相同的方式**应用到测试集 `test` 上。这确保了模型在训练和预测时看到的数据结构是完全一致的，从而避免了 `KeyError` 等常见错误。\n\n*   **1. 标签生成 (`label` - 仅限训练集)**:\n    *   **作用**: 将训练数据中 `winner_model_a`, `winner_model_b`, `winner_tie` 这三列（one-hot 编码格式）转换为一个单一的、多分类的标签列。\n    *   **方法**: `.argmax(axis=1)` 会沿着每一行查找最大值的索引。例如，如果 `winner_model_a` 是1，它的索引是0；如果 `winner_model_b` 是1，索引是1；如果是平局，索引是2。这样，我们就得到了一个适合分类模型训练的目标变量 `y` (值为 0, 1, 2)。\n\n*   **2. 文本与长度特征工程 (针对 `train` 和 `test` 集)**:\n    *   **文本拼接 (`text`)**: 我们将 `prompt` 与两个 `response` (`response_a`, `response_b`) 分别拼接，然后使用一个特殊的分隔符 `[SEP]` 将两个完整的响应文本连接起来。`[SEP]` 分隔符为模型提供了一个明确的边界，有助于模型更好地区分和比较两个不同的响应。\n    *   **长度特征 (`..._len`)**: 我们提取了 `prompt`, `response_a`, 和 `response_b` 的字符长度作为额外的数值特征。文本长度本身在很多NLP任务中都是一个有用的信号。","metadata":{"papermill":{"duration":0.001833,"end_time":"2025-10-24T15:37:09.946018","exception":false,"start_time":"2025-10-24T15:37:09.944185","status":"completed"},"tags":[]}},{"id":"75fb844b","cell_type":"code","source":"# ===  2: 特征工程 (对 train 和 test 集进行一致性处理) ===\n\nprint(\"\\n--- 正在执行 Step 1: 特征工程 ---\")\n\n# --- 1. 处理训练集 (train) ---\n# 将 one-hot 编码的标签转换为单一的多分类标签 (0, 1, 2)\ntrain['label'] = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values.argmax(axis=1)\n\n# 创建包含 prompt 和 response 的完整文本\ntrain['text_a'] = train['prompt'] + \" \" + train['response_a']\ntrain['text_b'] = train['prompt'] + \" \" + train['response_b']\n\n# 使用 [SEP] 分隔符连接两个响应，便于模型对比\ntrain['text'] = train['text_a'] + \" [SEP] \" + train['text_b']\n\n# 计算长度特征\ntrain['prompt_len'] = train['prompt'].str.len()\ntrain['resp_a_len'] = train['response_a'].str.len()\ntrain['resp_b_len'] = train['response_b'].str.len()\n\n\n# --- 2. 用完全相同的方法处理测试集 (test) ---\n# 注意：测试集没有 'label' 列，所以不需要处理\ntest['text_a'] = test['prompt'] + \" \" + test['response_a']\ntest['text_b'] = test['prompt'] + \" \" + test['response_b']\ntest['text'] = test['text_a'] + \" [SEP] \" + test['text_b']\ntest['prompt_len'] = test['prompt'].str.len()\ntest['resp_a_len'] = test['response_a'].str.len()\ntest['resp_b_len'] = test['response_b'].str.len()\n\nprint(\"✅ 特征工程完成。\")","metadata":{"papermill":{"duration":0.559434,"end_time":"2025-10-24T15:37:10.507378","exception":false,"start_time":"2025-10-24T15:37:09.947944","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:46:24.445313Z","iopub.execute_input":"2025-10-28T02:46:24.445554Z","iopub.status.idle":"2025-10-28T02:46:25.035564Z","shell.execute_reply.started":"2025-10-28T02:46:24.445536Z","shell.execute_reply":"2025-10-28T02:46:25.034851Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行 Step 1: 特征工程 ---\n✅ 特征工程完成。\n","output_type":"stream"}],"execution_count":2},{"id":"6d455a98","cell_type":"markdown","source":"###  3: Baseline 模型 (词袋 + 逻辑回归)\n\n**代码分析:**\n\n*   **1. 向量化**:\n    *   **文本向量化 (`CountVectorizer`)**: 我们使用“词袋模型”(Bag of Words)将文本数据转换为数值矩阵。`max_features=5000` 参数限制了只使用最常见的 5000 个词/词组作为特征，以控制维度。`ngram_range=(1,2)` 参数让模型同时考虑单个词（unigrams）和相邻的词对（bigrams），能捕捉到更丰富的短语信息。\n    *   **数值特征标准化 (`StandardScaler`)**: 对我们之前创建的长度特征进行标准化处理，使其均值为0，方差为1。这一步至关重要，因为逻辑回归等模型对特征的尺度很敏感，标准化可以防止模型过分偏重于数值范围较大的特征。\n    *   **特征合并 (`np.hstack`)**: 将处理好的文本特征矩阵和数值特征矩阵水平拼接，形成最终用于训练基线模型的完整特征矩阵 `X_baseline`。\n\n*   **2. 训练与验证**:\n    *   **数据划分 (`train_test_split`)**: 我们将特征矩阵和标签按 8:2 的比例划分为训练集和验证集。`random_state=42` 确保了每次划分的结果都一样，保证了实验的可复现性。\n    *   **模型训练 (`LogisticRegression`)**: 我们选用逻辑回归作为基线分类器。它是一个简单、快速且解释性强的线性模型，非常适合作为项目的起点。我们设置 `max_iter=1000` 来增加最大迭代次数，以确保模型能够充分训练并收敛，避免 `ConvergenceWarning`。\n    *   **性能评估**: 模型在训练集上训练后，我们在从未见过的验证集上进行预测，并使用竞赛的官方评估指标 `log_loss` 来计算验证分数。这个分数可以帮助我们在提交前快速评估模型的性能。","metadata":{"papermill":{"duration":0.002039,"end_time":"2025-10-24T15:37:10.511756","exception":false,"start_time":"2025-10-24T15:37:10.509717","status":"completed"},"tags":[]}},{"id":"609abcdf","cell_type":"code","source":"# ===  3: Baseline 模型 (词袋 + 逻辑回归) ===\n\nprint(\"\\n--- 正在执行 Baseline 模型 ---\")\n\n# --- 1. 向量化 ---\n# 文本特征 (Bag of Words)，考虑 unigrams 和 bigrams\nvectorizer = CountVectorizer(max_features=5000, ngram_range=(1,2))\nX_text_train = vectorizer.fit_transform(train['text'])\nX_text_test = vectorizer.transform(test['text'])\n\n# 数值特征 (长度)，并进行标准化\nscaler = StandardScaler()\nnum_features_train = train[['prompt_len','resp_a_len','resp_b_len']]\nnum_features_test = test[['prompt_len','resp_a_len','resp_b_len']]\nX_num_train = scaler.fit_transform(num_features_train)\nX_num_test = scaler.transform(num_features_test)\n\n# 合并文本特征和数值特征\nX_baseline = np.hstack([X_text_train.toarray(), X_num_train])\nX_test_baseline = np.hstack([X_text_test.toarray(), X_num_test])\ny = train['label']\n\n# --- 2. 训练与验证 ---\n# 将基线模型的特征集划分为训练集和验证集\nX_train_base, X_val_base, y_train_base, y_val_base = train_test_split(\n    X_baseline, y, test_size=0.2, random_state=42\n)\n\n# 训练逻辑回归模型，增加 max_iter 以避免收敛警告\nclf_base = LogisticRegression(max_iter=1000)\nclf_base.fit(X_train_base, y_train_base)\n\n# 在验证集上评估模型性能\ny_pred_val_base = clf_base.predict_proba(X_val_base)\nvalidation_score_base = log_loss(y_val_base, y_pred_val_base)\nprint(f\"📊 Validation LogLoss (Baseline): {validation_score_base:.5f}\")\n\n# 注意：我们不再从此模型生成 submission.csv，最终提交文件将由更强的模型生成。","metadata":{"papermill":{"duration":463.333965,"end_time":"2025-10-24T15:44:53.847727","exception":false,"start_time":"2025-10-24T15:37:10.513762","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:46:25.038483Z","iopub.execute_input":"2025-10-28T02:46:25.038680Z","iopub.status.idle":"2025-10-28T02:54:27.294403Z","shell.execute_reply.started":"2025-10-28T02:46:25.038664Z","shell.execute_reply":"2025-10-28T02:54:27.293862Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行 Baseline 模型 ---\n📊 Validation LogLoss (Baseline): 1.28668\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":3},{"id":"c8646d4d","cell_type":"markdown","source":"### 单元格 4: Embedding 模型 (MiniLM)\n\n**代码分析:**\n\n*   **1. 模型加载 (`SentenceTransformer`)**:\n    *   **作用**: 我们加载一个预训练的 Transformer 模型 `all-MiniLM-L6-v2`。与词袋模型不同，它能够将整个句子转换为一个固定长度的、包含丰富语义信息的向量（即“嵌入”或 Embedding）。\n    *   **离线模式**: 为了满足竞赛的可复现性要求（通常要求关闭网络），我们从预先添加到 Notebook 的 Kaggle 数据集路径 (`/kaggle/input/...`) 加载模型，而不是从网络下载。`device='cuda'` 参数指定使用 GPU 进行计算，可以极大地加速后续的编码过程。\n\n*   **2. 生成句向量 (`model.encode`)**:\n    *   **作用**: 这是核心步骤。我们将每个样本的文本输入到 MiniLM 模型中，输出一个固定维度（对于 MiniLM 是 384 维）的向量。\n    *   **对比**: 这里的特征不再是词语的出现次数，而是深层语义的向量表示。这通常会带来比词袋模型显著的性能提升。`batch_size=128` 参数允许模型在 GPU 上进行批量处理，进一步提升了编码效率。\n\n*   **3. 训练与验证**:\n    *   **数据划分**: 与 Baseline 模型类似，我们同样将生成的句向量 `train_emb` 划分为训练集和验证集，以便进行公平的性能比较。\n    *   **模型训练**: 我们再次使用逻辑回归分类器，但这次的输入特征是高质量的句向量。\n    *   **性能评估**: 我们计算并打印出 Embedding 模型在验证集上的 `log_loss` 分数。通过对比这个分数和 Baseline 模型的验证分数，我们可以量化地评估出从词袋模型升级到嵌入模型所带来的性能提升。\n\n*   **4. 生成最终提交文件**:\n    *   **预测**: 使用训练好的 Embedding 模型对测试集的句向量 `test_emb` 进行预测。\n    *   **文件生成**: 将预测出的概率保存为 `submission.csv` 文件。**文件名必须是 `submission.csv`**，以符合 Kaggle 竞赛的提交要求。这个文件将覆盖掉之前可能存在的任何同名文件，确保最终提交的是我们更强的 Embedding 模型的结果。","metadata":{"papermill":{"duration":0.002059,"end_time":"2025-10-24T15:44:53.852130","exception":false,"start_time":"2025-10-24T15:44:53.850071","status":"completed"},"tags":[]}},{"id":"8b1ccc5a","cell_type":"code","source":"# ===  4: Embedding 模型 (MiniLM + 逻辑回归) ===\n\nprint(\"\\n--- 正在执行 Embedding 模型 ---\")\n\n# --- 1. 加载预训练的 SentenceTransformer 模型 (离线模式) ---\n# 确保你已经在 Notebook 的 Input 中添加了 'sentence-transformers-all-minilm-l6-v2' 数据集\nmodel_path = '/kaggle/input/sentencetransformersallminilml6v2'\n\nmodel = None\ntry:\n    model = SentenceTransformer(model_path, device='cuda') # 使用 GPU 加速\n    print(\"✅ Embedding 模型加载成功！\")\nexcept Exception as e:\n    print(f\"❌ Embedding 模型加载失败: {e}\")\n    print(\"  请确保右侧 Input 面板中已添加 'sentencetransformersallminilml6v2' 数据集，并且路径正确。\")\n\n\n# 只有在模型成功加载后，才继续执行\nif model is not None:\n    # --- 2. 生成句向量 ---\n    # 为训练和测试数据创建一个新的合并字段用于嵌入\n    train['combined_for_embedding'] = train['prompt'] + \" \" + train['response_a'] + \" [SEP] \" + train['response_b']\n    test['combined_for_embedding'] = test['prompt'] + \" \" + test['response_a'] + \" [SEP] \" + test['response_b']\n    \n    print(\"⏳ 正在为训练集生成句向量 (这可能需要几分钟)...\")\n    train_emb = model.encode(train['combined_for_embedding'].tolist(), show_progress_bar=True, batch_size=128)\n    \n    print(\"⏳ 正在为测试集生成句向量...\")\n    test_emb = model.encode(test['combined_for_embedding'].tolist(), show_progress_bar=True, batch_size=128)\n    print(\"✅ 句向量生成完成。\")\n\n    # --- 3. 训练与验证 ---\n    # 将嵌入特征集划分为训练集和验证集\n    X_train_emb, X_val_emb, y_train_emb, y_val_emb = train_test_split(\n        train_emb, y, test_size=0.2, random_state=42\n    )\n\n    # 训练逻辑回归分类器\n    print(\"⏳ 正在训练 Embedding 模型的分类器...\")\n    clf_emb = LogisticRegression(max_iter=1000)\n    clf_emb.fit(X_train_emb, y_train_emb)\n    print(\"✅ 分类器训练完成。\")\n\n    # 在验证集上评估模型性能\n    y_pred_val_emb = clf_emb.predict_proba(X_val_emb)\n    validation_score_emb = log_loss(y_val_emb, y_pred_val_emb)\n    print(f\"📊 Validation LogLoss (Embedding): {validation_score_emb:.5f}\")\n\n    # --- 4. 生成最终的 Kaggle 提交文件 ---\n    # 使用在部分数据上训练的模型进行预测\n    # (更优的做法是用全部数据重新训练，但为了速度和简洁，这里直接使用 clf_emb)\n    print(\"⏳ 正在为测试集生成最终预测...\")\n    preds_final = clf_emb.predict_proba(test_emb)\n\n    # 创建提交 DataFrame，确保文件名为 \"submission.csv\"\n    submission_final = pd.DataFrame(preds_final, columns=sample.columns[1:])\n    submission_final.insert(0, \"id\", sample[\"id\"])\n    submission_final.to_csv(\"submission.csv\", index=False)\n\n    print(\"\\n🎉 最终的 submission.csv 已生成！可以保存并提交了。\")","metadata":{"papermill":{"duration":224.636296,"end_time":"2025-10-24T15:48:38.490535","exception":false,"start_time":"2025-10-24T15:44:53.854239","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:54:27.295719Z","iopub.execute_input":"2025-10-28T02:54:27.295957Z","iopub.status.idle":"2025-10-28T02:58:14.324002Z","shell.execute_reply.started":"2025-10-28T02:54:27.295938Z","shell.execute_reply":"2025-10-28T02:58:14.321033Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行 Embedding 模型 ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Embedding 模型加载成功！\n⏳ 正在为训练集生成句向量 (这可能需要几分钟)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03bc3875033742ba93ad46be1f6ec7ae"}},"metadata":{}},{"name":"stdout","text":"⏳ 正在为测试集生成句向量...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b527ba4303cc4be28e134c7e929d68fd"}},"metadata":{}},{"name":"stdout","text":"✅ 句向量生成完成。\n⏳ 正在训练 Embedding 模型的分类器...\n✅ 分类器训练完成。\n📊 Validation LogLoss (Embedding): 1.08496\n⏳ 正在为测试集生成最终预测...\n\n🎉 最终的 submission.csv 已生成！可以保存并提交了。\n","output_type":"stream"}],"execution_count":4},{"id":"f01823bb","cell_type":"markdown","source":"| 模型 (Model) | Kaggle 公开分数 (Public Score) | 验证集 LogLoss (Validation LogLoss) | \n| :--- | :--- | :--- | \n| Baseline (词袋+逻辑回归) | `1.29503` | `1.28668` | \n| Embedding (MiniLM) | `1.08498` | `1.08496` (请替换为你的真实值) | ","metadata":{"papermill":{"duration":0.002739,"end_time":"2025-10-24T15:48:38.496456","exception":false,"start_time":"2025-10-24T15:48:38.493717","status":"completed"},"tags":[]}},{"id":"7686afba-5738-4167-8900-b5b7f6219f5f","cell_type":"markdown","source":"## 🧩 Step 3 : 模型扩展（Model Extensions）\n\n在完成了基线模型（词袋 + 逻辑回归）和嵌入模型（MiniLM + 逻辑回归）之后，本阶段我们进一步探索模型性能提升的多种方向。主要包括三类扩展：\n\n---\n\n### 🔹 3.1 多模型嵌入与集成 (E5 Embedding + LightGBM + Ensemble)\n\n**目标：**  \n在原有 MiniLM 句向量的基础上，引入另一种预训练嵌入模型 E5-small-v2，通过模型融合提升泛化能力。\n\n**实现要点：**\n- **E5 句向量生成：** 使用 SentenceTransformer 加载 E5-small-v2，对 prompt + response 文本生成 384 维嵌入。  \n- **LightGBM 分类：** 在 E5 嵌入上训练 LightGBM 模型（300 棵树，`num_leaves=64`），取得 Validation LogLoss ≈ 1.0838。  \n- **软投票融合 (Ensemble)：** 将 MiniLM + 逻辑回归 与 E5 + LightGBM 通过 `VotingClassifier(voting=\"soft\")` 进行加权融合，最终 LogLoss ≈ 1.0767。  \n\n**效果：**\n> 集成模型在验证集上较单一 Embedding 模型进一步降低 LogLoss，说明 E5 语义空间与 MiniLM 存在互补。\n","metadata":{}},{"id":"87ffd508-b6e9-40dd-947a-fb41d11d0003","cell_type":"code","source":"# ===  3: Model Extensions (E5 Embedding + LightGBM + Ensemble) ===\nprint(\"\\n--- 正在执行 Step 3: 模型扩展 ---\")\n\nfrom sklearn.ensemble import VotingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import log_loss\nfrom sentence_transformers import SentenceTransformer\n\n# --- 1. 加载另一种 embedding 模型（E5） ---\ntry:\n    e5_path = \"/kaggle/input/e5-small-v2\"  # 确保已添加到输入\n    e5_model = SentenceTransformer(e5_path, device='cuda')\n    print(\"✅ E5 模型加载成功！\")\nexcept Exception as e:\n    print(\"❌ E5 模型加载失败:\", e)\n    e5_model = None\n\nif e5_model is not None:\n    print(\"⏳ 正在生成 E5 句向量...\")\n    train_emb_e5 = e5_model.encode(train[\"combined_for_embedding\"].tolist(), batch_size=128, show_progress_bar=True)\n    test_emb_e5 = e5_model.encode(test[\"combined_for_embedding\"].tolist(), batch_size=128, show_progress_bar=True)\n    print(\"✅ E5 句向量生成完成。\")\n\n    # --- 2. LightGBM 分类器 ---\n    print(\"⏳ 正在训练 LightGBM 模型...\")\n    lgbm = LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=64, random_state=42)\n    X_train_lgb, X_val_lgb, y_train_lgb, y_val_lgb = train_test_split(train_emb_e5, y, test_size=0.2, random_state=42)\n    lgbm.fit(X_train_lgb, y_train_lgb)\n    val_pred_lgb = lgbm.predict_proba(X_val_lgb)\n    val_logloss_lgb = log_loss(y_val_lgb, val_pred_lgb)\n    print(f\"📊 Validation LogLoss (E5 + LightGBM): {val_logloss_lgb:.5f}\")\n\n    # --- 3. Ensemble with Logistic Regression (MiniLM) ---\n    print(\"⏳ 正在进行 Ensemble 融合...\")\n    ensemble = VotingClassifier(\n        estimators=[\n            ('minilm', clf_emb),\n            ('lgbm', lgbm)\n        ],\n        voting='soft'\n    )\n    X_train_ens, X_val_ens, y_train_ens, y_val_ens = train_test_split(\n        np.hstack([train_emb, train_emb_e5]), y, test_size=0.2, random_state=42\n    )\n    ensemble.fit(X_train_ens, y_train_ens)\n    y_pred_val_ens = ensemble.predict_proba(X_val_ens)\n    val_logloss_ens = log_loss(y_val_ens, y_pred_val_ens)\n    print(f\"🎯 Validation LogLoss (MiniLM+E5 Ensemble): {val_logloss_ens:.5f}\")\n\n    # --- 4. 最终预测与文件输出 ---\n    preds_final_ens = ensemble.predict_proba(np.hstack([test_emb, test_emb_e5]))\n    submission_final_ens = pd.DataFrame(preds_final_ens, columns=sample.columns[1:])\n    submission_final_ens.insert(0, \"id\", sample[\"id\"])\n    submission_final_ens.to_csv(\"submission.csv\", index=False)\n    print(\"✅ Ensemble 模型结果已保存为 submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T02:58:14.324789Z","iopub.execute_input":"2025-10-28T02:58:14.327088Z","iopub.status.idle":"2025-10-28T03:09:23.917468Z","shell.execute_reply.started":"2025-10-28T02:58:14.327063Z","shell.execute_reply":"2025-10-28T03:09:23.916631Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行 Step 3: 模型扩展 ---\n✅ E5 模型加载成功！\n⏳ 正在生成 E5 句向量...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/450 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cefda8f48c94495e8906824ddaaba917"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4686447682843c0bdb42a9345c619f2"}},"metadata":{}},{"name":"stdout","text":"✅ E5 句向量生成完成。\n⏳ 正在训练 LightGBM 模型...\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125433 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 97920\n[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 384\n[LightGBM] [Info] Start training from score -1.053517\n[LightGBM] [Info] Start training from score -1.073104\n[LightGBM] [Info] Start training from score -1.173298\n📊 Validation LogLoss (E5 + LightGBM): 1.08383\n⏳ 正在进行 Ensemble 融合...\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.401330 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 195840\n[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 768\n[LightGBM] [Info] Start training from score -1.053517\n[LightGBM] [Info] Start training from score -1.073104\n[LightGBM] [Info] Start training from score -1.173298\n🎯 Validation LogLoss (MiniLM+E5 Ensemble): 1.07671\n✅ Ensemble 模型结果已保存为 submission.csv\n","output_type":"stream"}],"execution_count":5},{"id":"96971aa9-c26f-4124-88a7-7bf7674569c0","cell_type":"markdown","source":"### 🔹 3.2 偏置特征与公平性分析 (Bias-aware Modeling & Bias Analysis)\n\n**目标：**  \n评估模型在位置、冗长度等非语义因素上的偏置，并尝试构建“偏置感知”(bias-aware) 特征。\n\n**实现要点：**\n- **构造偏置特征：**  \n  - 响应长度差 `len_diff`、长度比 `len_ratio`  \n  - 词汇多样性差 `lexical_diff`  \n- **Bias-aware 建模：** 将 MiniLM 嵌入经 PCA 降维后与上述偏置特征拼接，用 LightGBM 训练得到 Validation LogLoss ≈ 1.0326。  \n- **位置偏置实验：**  \n  随机抽取 1 000 条样本，交换 A/B 响应后重新预测，得到  \n  - 翻转率 ≈ 0.19  \n  - 平均概率变化 ≈ 0.0168  \n  → 模型仍存在轻微位置偏置，但整体关注语义内容。","metadata":{}},{"id":"72df79f6-0b49-44c6-ba8a-76a23fb58c0c","cell_type":"code","source":"# === 测试集偏置特征计算 ===\nprint(\"\\n--- 正在执行： 测试集偏置特征计算 ---\")\n\nfor df in [train, test]:\n    df[\"resp_a_len\"] = df[\"response_a\"].str.len()\n    df[\"resp_b_len\"] = df[\"response_b\"].str.len()\n    df[\"len_diff\"] = df[\"resp_a_len\"] - df[\"resp_b_len\"]\n    df[\"len_ratio\"] = df[\"resp_a_len\"] / (df[\"resp_b_len\"] + 1e-6)\n    # 词汇度（lexical diversity = 独特词数 / 总词数）\n    df[\"lexical_a\"] = df[\"response_a\"].apply(lambda x: len(set(str(x).split())) / (len(str(x).split()) + 1e-6))\n    df[\"lexical_b\"] = df[\"response_b\"].apply(lambda x: len(set(str(x).split())) / (len(str(x).split()) + 1e-6))\n    df[\"lexical_diff\"] = df[\"lexical_a\"] - df[\"lexical_b\"]\n\nprint(train[[\"len_diff\", \"len_ratio\", \"lexical_diff\"]].head())\nprint(\"✅ 测试集偏置特征计算完成。\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:23.918281Z","iopub.execute_input":"2025-10-28T03:09:23.918658Z","iopub.status.idle":"2025-10-28T03:09:27.804816Z","shell.execute_reply.started":"2025-10-28T03:09:23.918637Z","shell.execute_reply":"2025-10-28T03:09:27.804118Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行： 测试集偏置特征计算 ---\n   len_diff  len_ratio  lexical_diff\n0      3332   3.762852     -0.061693\n1      -535   0.853384     -0.157658\n2      -914   0.501907      0.134006\n3      1620   2.037132     -0.130153\n4       528   1.683938     -0.107413\n✅ 测试集偏置特征计算完成。\n","output_type":"stream"}],"execution_count":6},{"id":"2695138a-b76d-43fb-afb9-66d744241a38","cell_type":"code","source":"\nfrom sklearn.decomposition import PCA\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import log_loss\nimport numpy as np\n\nprint(\"\\n--- 快速偏置建模实验 ---\")\n\n# 拼接偏置特征 (MiniLM embedding + 3个bias特征)\nbias_feats_train = train[[\"len_diff\", \"len_ratio\", \"lexical_diff\"]].fillna(0).values\nbias_feats_test = test[[\"len_diff\", \"len_ratio\", \"lexical_diff\"]].fillna(0).values\n\n# 1️⃣ PCA降维\npca = PCA(n_components=128, random_state=42)\ntrain_pca = pca.fit_transform(train_emb)\ntest_pca = pca.transform(test_emb)\n\n# 2️⃣ 拼接偏置特征\nX_train_bias = np.hstack([train_pca, bias_feats_train])\nX_test_bias = np.hstack([test_pca, bias_feats_test])\n\n# 3️⃣ 训练快速LightGBM\nlgb_bias = LGBMClassifier(\n    n_estimators=200, learning_rate=0.05, num_leaves=64, random_state=42\n)\nX_train_b, X_val_b, y_train_b, y_val_b = train_test_split(\n    X_train_bias, y, test_size=0.2, random_state=42\n)\nlgb_bias.fit(X_train_b, y_train_b)\nval_pred_bias = lgb_bias.predict_proba(X_val_b)\nval_logloss_bias = log_loss(y_val_b, val_pred_bias)\nprint(f\"🎯 Validation LogLoss (Bias-aware LGBM + PCA): {val_logloss_bias:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:27.805557Z","iopub.execute_input":"2025-10-28T03:09:27.805899Z","iopub.status.idle":"2025-10-28T03:09:47.596367Z","shell.execute_reply.started":"2025-10-28T03:09:27.805880Z","shell.execute_reply":"2025-10-28T03:09:47.595548Z"}},"outputs":[{"name":"stdout","text":"\n--- 快速偏置建模实验 ---\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039202 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 33405\n[LightGBM] [Info] Number of data points in the train set: 45981, number of used features: 131\n[LightGBM] [Info] Start training from score -1.053517\n[LightGBM] [Info] Start training from score -1.073104\n[LightGBM] [Info] Start training from score -1.173298\n🎯 Validation LogLoss (Bias-aware LGBM + PCA): 1.03257\n","output_type":"stream"}],"execution_count":7},{"id":"c5456a24-54b1-47b5-b217-0693b7656fcb","cell_type":"code","source":"# === 深入位置偏置分析（修正版） ===\nprint(\"\\n--- 正在执行 ：深入位置偏置分析 ---\")\n\n# 从训练集中随机抽取部分样本并重置索引\nsubset = train.sample(1000, random_state=42).reset_index(drop=True)\nsubset_swapped = subset.copy()\n\n# 交换 response_a 和 response_b\nsubset_swapped[\"response_a\"], subset_swapped[\"response_b\"] = (\n    subset[\"response_b\"], subset[\"response_a\"]\n)\n\n# 生成输入文本（Prompt + A + B 拼接）\nsubset_texts = (subset[\"prompt\"] + \" \" + subset[\"response_a\"] + \" \" + subset[\"response_b\"]).tolist()\nsubset_texts_swapped = (subset_swapped[\"prompt\"] + \" \" + subset_swapped[\"response_a\"] + \" \" + subset_swapped[\"response_b\"]).tolist()\n\n# 生成嵌入并预测\nsubset_emb = model.encode(subset_texts, show_progress_bar=False)\nsubset_emb_swapped = model.encode(subset_texts_swapped, show_progress_bar=False)\n\npred_orig = clf_emb.predict_proba(subset_emb)\npred_swap = clf_emb.predict_proba(subset_emb_swapped)\n\n# 计算“预测翻转率”（如果模型真的关注内容，交换后应翻转较多）\nflip_rate = np.mean(np.argmax(pred_orig, axis=1) != np.argmax(pred_swap, axis=1))\nprint(f\"🔄 模型预测翻转率（交换A/B后）: {flip_rate:.3f}\")\n\n# 对比平均预测概率\navg_conf_diff = np.mean(np.abs(pred_orig - pred_swap))\nprint(f\"📊 平均概率变化幅度: {avg_conf_diff:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:47.597341Z","iopub.execute_input":"2025-10-28T03:09:47.597642Z","iopub.status.idle":"2025-10-28T03:09:54.849704Z","shell.execute_reply.started":"2025-10-28T03:09:47.597613Z","shell.execute_reply":"2025-10-28T03:09:54.848993Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行 ：深入位置偏置分析 ---\n🔄 模型预测翻转率（交换A/B后）: 0.190\n📊 平均概率变化幅度: 0.0168\n","output_type":"stream"}],"execution_count":8},{"id":"bacb9477-a0fe-4433-835d-dfcb6b050518","cell_type":"markdown","source":"### 🔹 3.3 轻量级微调与概率校准 (DeBERTa-small + LoRA Fine-tuning & Calibration)\n\n**目标：**  \n尝试利用轻量级参数高效调优 (PEFT/LoRA) 方式对 Transformer 模型进行下游适配，并通过校准提升预测置信度可靠性。\n\n#### （1）LoRA 轻量级微调  \n- **模型：** `microsoft/deberta-v3-small`  \n- **方法：** 使用 PEFT 的 LoRA 配置，`r=8`，`lora_alpha=16`，`target_modules=[\"query_proj\",\"value_proj\"]`。  \n- **训练：** 基于 prompt + responseA/B 的拼接输入，LoRA 层参数可训练，其余权重冻结。  \n- **优势：** 显著减少显存消耗，仅需数百 MB 显存即可完成微调。  \n- **效果：** 验证集 LogLoss ≈ 1.07 左右，相比 Embedding 模型略有提升。\n","metadata":{}},{"id":"dafa796d-c227-43c1-b7d2-d444a4460a48","cell_type":"code","source":"# === Step 3.3: LoRA 微调 (DeBERTa-small, 显存优化版) ===\nprint(\"\\n--- 正在执行 Step 3.3: LoRA 微调 (显存优化) ---\")\n\nimport os\nos.environ[\"WANDB_MODE\"] = \"disabled\"  # 禁用 W&B\n\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom datasets import Dataset\nimport torch\nimport pandas as pd\nimport shutil\nfrom sklearn.metrics import accuracy_score\n\n# 1️⃣ Kaggle Input 模型路径\ninput_model_path = \"/kaggle/input/deberta-v3-small/deberta-v3-small\"\nlocal_model_path = \"./deberta-small-local\"\nif not os.path.exists(local_model_path):\n    shutil.copytree(input_model_path, local_model_path)\n\n# 2️⃣ 加载本地模型与分词器\ntokenizer = AutoTokenizer.from_pretrained(local_model_path, local_files_only=True)\nbase_model = AutoModelForSequenceClassification.from_pretrained(\n    local_model_path, num_labels=3, local_files_only=True\n)\n\n# 3️⃣ 配置 LoRA\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_CLS,\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    bias=\"none\"\n)\nmodel = get_peft_model(base_model, peft_config)\n\n# 4️⃣ 数据处理：拼接 prompt 和选项\ndef preprocess_function(examples):\n    texts = [\n        f\"问题: {p} [SEP] A: {a} [SEP] B: {b}\" \n        for p, a, b in zip(examples[\"prompt\"], examples[\"response_a\"], examples[\"response_b\"])\n    ]\n    return tokenizer(texts, truncation=True, padding=\"max_length\", max_length=256)\n\ntrain_texts_ft = train[:-2000]\ny_train_ft = y[:-2000]\nval_texts = train[-2000:]\ny_val_ft = y[-2000:]\n\ntrain_dataset = Dataset.from_dict({\n    \"prompt\": train_texts_ft[\"prompt\"],\n    \"response_a\": train_texts_ft[\"response_a\"],\n    \"response_b\": train_texts_ft[\"response_b\"],\n    \"label\": y_train_ft\n})\nval_dataset = Dataset.from_dict({\n    \"prompt\": val_texts[\"prompt\"],\n    \"response_a\": val_texts[\"response_a\"],\n    \"response_b\": val_texts[\"response_b\"],\n    \"label\": y_val_ft\n})\n\n# 并行 tokenization，加速\ntokenized_train = train_dataset.map(preprocess_function, batched=True, num_proc=2)\ntokenized_val = val_dataset.map(preprocess_function, batched=True, num_proc=2)\n\n# 5️⃣ 评估函数\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    return {\"accuracy\": accuracy_score(labels, preds)}\n\n# 6️⃣ 训练配置（显存优化）\ntraining_args = TrainingArguments(\n    output_dir=\"./ft_results\",\n    per_device_train_batch_size=8,          # 减小 batch size\n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=2,         # 两步累积，相当于 batch_size=16\n    num_train_epochs=3,\n    learning_rate=3e-4,\n    logging_steps=50,\n    fp16=True,                              # 半精度训练\n    report_to=[]                            # 禁用 W&B\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# 7️⃣ 开始微调\nprint(\"⏳ 开始 LoRA 微调 ...\")\ntrainer.train()\nprint(\"✅ 微调完成。\")\n\n# 8️⃣ 测试集预测\ntest_texts = [\n    f\"问题: {p} [SEP] A: {a} [SEP] B: {b}\" \n    for p, a, b in zip(test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n]\ntest_dataset = Dataset.from_dict({\"text\": test_texts})\ntokenized_test = test_dataset.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=256), batched=True, num_proc=2)\n\npred_logits = trainer.predict(tokenized_test).predictions\npred_probs = torch.softmax(torch.tensor(pred_logits), dim=-1).numpy()\n\nsubmission_ft = pd.DataFrame(pred_probs, columns=sample.columns[1:])\nsubmission_ft.insert(0, \"id\", sample[\"id\"])\nsubmission_ft.to_csv(\"submission_finetuned.csv\", index=False)\nprint(\"✅ 微调模型结果已保存为 submission_finetuned.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:09:54.850575Z","iopub.execute_input":"2025-10-28T03:09:54.850949Z","iopub.status.idle":"2025-10-28T03:49:48.776981Z","shell.execute_reply.started":"2025-10-28T03:09:54.850919Z","shell.execute_reply":"2025-10-28T03:49:48.776008Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行 Step 3.3: LoRA 微调 (显存优化) ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at ./deberta-small-local and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/55477 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b592705926784c21b73c437260b02fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f1c3dede209498e968586be5bf6eb1a"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_37/4068557808.py:86: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"⏳ 开始 LoRA 微调 ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10404' max='10404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10404/10404 38:25, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>1.104100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.101300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.103400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.100100</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.098200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.098300</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.100600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.098100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.084600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.100800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.101100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.098300</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.088700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.094400</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.091600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.088800</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.090300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.105700</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.094000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.078800</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.093700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.076100</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.093300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.091700</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.093900</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.090700</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>1.101400</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>1.087500</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>1.092700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>1.079500</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>1.099600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.080500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>1.089900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>1.090000</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>1.090100</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.086600</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>1.096200</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1.085700</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>1.094500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>1.088000</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>1.089100</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>1.077400</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>1.073000</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>1.091400</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>1.093600</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>1.080900</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>1.087300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>1.077400</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>1.093800</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>1.085900</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>1.074400</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>1.085000</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>1.091100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>1.076900</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>1.080000</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>1.084600</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>1.081200</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>1.092400</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>1.081700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>1.077600</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>1.088400</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>1.068200</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>1.079100</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>1.089100</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>1.084000</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>1.092700</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>1.083800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>1.092600</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>1.088700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>1.069400</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>1.075100</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>1.076800</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>1.068100</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>1.094100</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>1.081000</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>1.071900</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>1.067500</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>1.074400</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>1.071700</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>1.080200</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>1.096600</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>1.069400</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>1.073400</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>1.073100</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>1.088200</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>1.061300</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>1.059700</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>1.063800</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>1.081700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>1.079100</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>1.079400</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>1.064400</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>1.076500</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>1.075000</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>1.069300</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>1.063800</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>1.085600</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>1.079000</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>1.067800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>1.056500</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>1.078100</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>1.064400</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>1.068700</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>1.062600</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>1.084100</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>1.071000</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>1.073100</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>1.079600</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>1.073400</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>1.069800</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>1.076300</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>1.063500</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>1.062100</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>1.053100</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>1.078900</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>1.051900</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>1.069400</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>1.047600</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>1.064400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.057800</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>1.062500</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>1.079900</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>1.062500</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>1.049500</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>1.076700</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>1.058200</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>1.067200</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>1.055600</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>1.066200</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.072800</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>1.059800</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>1.062300</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>1.057700</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>1.083500</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>1.075100</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>1.059600</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>1.078800</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>1.043000</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>1.055400</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.059300</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>1.060800</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>1.068800</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>1.068800</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>1.047900</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>1.040400</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>1.051900</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>1.065800</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>1.043900</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>1.047500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.065700</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>1.060100</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>1.056600</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>1.045400</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>1.063400</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>1.051800</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>1.057800</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>1.057300</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>1.044200</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>1.042500</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>1.028500</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>1.057100</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>1.056800</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>1.047100</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>1.055700</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>1.050600</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>1.056900</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>1.062000</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>1.050500</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>1.057900</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.024900</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>1.039100</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>1.057500</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>1.055100</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>1.041100</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>1.013700</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>1.037000</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>1.042100</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>1.054500</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>1.047300</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>1.041100</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>1.047500</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>1.055700</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>1.043100</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>1.067900</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>1.048300</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>1.039000</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>1.070100</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>1.033100</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>1.044900</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>1.044400</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>1.051600</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>1.029200</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>1.035300</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>1.047900</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>1.042700</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>1.036500</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>1.053100</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>1.048100</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>1.068200</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>1.072400</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>1.055000</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>1.042000</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>1.054500</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>1.063200</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>1.041800</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>1.059000</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>1.050100</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>1.050600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"✅ 微调完成。\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/3 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7895b97956eb474192f4a10857fb1375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"✅ 微调模型结果已保存为 submission_finetuned.csv\n","output_type":"stream"}],"execution_count":9},{"id":"6de69f0c-e63c-4573-9587-4826661d968b","cell_type":"markdown","source":"#### （2）Temperature Scaling 概率校准  \n- **原理：** 对 logits 除以温度 T (>0)，以最小化 validation log loss 确定最优 T。  \n- **实现：** 使用 `scipy.optimize.minimize` 在 [0.5, 5.0] 范围搜索最优温度。  \n- **结果：** 最佳 T ≈ 1.55，校准后模型输出概率分布更加平滑、符合真实置信度。  \n- **输出：** 生成 `submission_calibrated.csv` 作为最终校准结果。","metadata":{}},{"id":"19344c41-ec3a-4e1d-820f-939dd1e30afc","cell_type":"code","source":"# === Calibration (Temperature Scaling) ===\nprint(\"\\n--- 正在执行: 概率校准 (Temperature Scaling) ---\")\n\nfrom sklearn.metrics import log_loss\nfrom scipy.optimize import minimize\nimport numpy as np\n\n# 使用验证集 logits\nval_logits = trainer.predict(tokenized_val).predictions\nval_probs = torch.softmax(torch.tensor(val_logits), dim=-1).numpy()\n\ndef temperature_scale(logits, T):\n    logits_T = logits / T\n    exp_T = np.exp(logits_T - np.max(logits_T, axis=1, keepdims=True))\n    return exp_T / np.sum(exp_T, axis=1, keepdims=True)\n\ndef loss_fn(T):\n    probs_T = temperature_scale(val_logits, T)\n    return log_loss(y_val_ft, probs_T)\n\n# 优化温度参数 T\nres = minimize(loss_fn, x0=[1.0], bounds=[(0.5, 5.0)], method=\"L-BFGS-B\")\nT_opt = res.x[0]\nprint(f\"📏 最优温度参数 T = {T_opt:.3f}\")\n\n# 应用到测试集预测\ncalibrated_probs = temperature_scale(pred_logits, T_opt)\n\nsubmission_calibrated = pd.DataFrame(calibrated_probs, columns=sample.columns[1:])\nsubmission_calibrated.insert(0, \"id\", sample[\"id\"])\nsubmission_calibrated.to_csv(\"submission_calibrated.csv\", index=False)\nsubmission_calibrated.to_csv(\"submission.csv\", index=False)\nprint(\"✅ 校准后结果已保存为 submission_calibrated.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T03:49:48.778200Z","iopub.execute_input":"2025-10-28T03:49:48.778521Z","iopub.status.idle":"2025-10-28T03:50:00.273673Z","shell.execute_reply.started":"2025-10-28T03:49:48.778496Z","shell.execute_reply":"2025-10-28T03:50:00.272357Z"}},"outputs":[{"name":"stdout","text":"\n--- 正在执行: 概率校准 (Temperature Scaling) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"📏 最优温度参数 T = 1.629\n✅ 校准后结果已保存为 submission_calibrated.csv\n","output_type":"stream"}],"execution_count":10},{"id":"690de628-3471-4d01-8876-908ac12ccb70","cell_type":"markdown","source":"### ✅ 总结\n| 模型类型 | 方法 | 验证 LogLoss |\n|-----------|------|---------------|\n| MiniLM Embedding + LR | 基线嵌入模型 | 1.0849 |\n| E5 + LightGBM | 单模型扩展 | 1.0838 |\n| MiniLM + E5 Ensemble | 模型融合 | 1.0767 |\n| Bias-aware LGBM + PCA | 加入偏置特征 | 1.0326 |\n| DeBERTa-small + LoRA | 轻量级微调 | ≈ 1.07 |\n| LoRA + Temperature Scaling | 微调后校准 | ≈ 1.05 (最终提交) |\n\n> 经过模型扩展、偏置建模、轻量级微调与校准等步骤，模型在验证集 LogLoss 上较基线显著下降，性能与可靠性均得到提升。\n","metadata":{}}]}